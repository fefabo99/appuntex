\chapter{Spazi vettoriali}
Gli spazi vettoriali sono degli insiemi con "sopra" delle struttre algebriche.

\section{Definizione di Spazi Vettoriali}
Sia $V$ un insieme e $K$ un "campo" (ad esempio $\R$).
Allora:

\definizione{
    Diremo che $V$ è uno \textbf{Spazio Vettoriale} su $K$ se esistono
    le operazioni di \textbf{Somma} ($+$) e di \textbf{Prodotto per uno scalare}($\cdot$) su $V$.
}
Nota che campo e spazio vettoriali non coincidono mai! se entrambi sono $\R$, allora sono copie diverse di esso.
\subsection{Le operazioni Somma e Prodotto}
Perchè un insieme sia uno spazio vettoriale deve essere dotato delle operazioni di Somma e Prodotto per uno scalare,
ma queste due operazioni devono rispettivamente verificare alcune proprietà.

\paragraph{Somma}
La somma è una funzione così definita:
\["+" : V \times V \to V \]
\begin{center}
    ovvero $(\underline{v_1}, \underline{v_2} ) \to "\underline{v_1} + \underline{v_2}\; \forall \underline{v_i} \in V"$.
\end{center}
    Essa deve godere delle seguenti proprietà:
\begin{enumerate}
    \item Nullo: $\exists \underline{0} \in V : \underline{0} + \underline{v} = v \; \forall \underline{v} \in V$
    \item Opposto: $\forall \underline{v} \in V, \exists "-\underline{v}" : \underline{v} + (-\underline{v}) = \underline{0}$
    \item Associatività: $(\underline{v_1} + \underline{v_2}) + \underline{v_3} = \underline{v_1} + (\underline{v_2} + \underline{v_3})$
    \item Commutatività: $\underline{v_1} + \underline{v_2} = \underline{v_2} + \underline{v_1}$
\end{enumerate}

\paragraph{Prodotto per uno Scalare}
Il Prodotto per uno Scalare è una funzione così definita:
\["\cdot" : K \times V \to V \]
\begin{center}
    ovvero $(\underline{\alpha}, \underline{v} ) \to "\alpha\underline{v}\;"$.
\end{center}
Essa deve godere delle seguenti proprietà:
\begin{enumerate}
    \item $(\lambda_1 + \lambda_2) \cdot \underline{v} = \lambda_1\underline{v} + \lambda_2 \underline{v}$ con $\lambda_i \in K, \underline{v} \in V$
    \item $\lambda \cdot (\underline{v_1} + \underline{v_1}) = \lambda\underline{v_1} + \lambda\underline{v_2}$ con $\lambda \in K, \underline{v_1} \in V$
    \item $(\lambda_1 \cdot \lambda_2) \cdot \underline{v} = \lambda_1 \cdot (\lambda_2 \cdot \underline{v})$
\end{enumerate}

\osservazione{Si può dimostrare che:
\begin{itemize}
    \item $0 \cdot \underline{v} = \underline{0} \; \forall \underline{v} \in V$
    \item $\lambda \cdot \underline{0} = \underline{0} \; \forall \lambda \in K$
    \item $-1 \cdot \underline{v} = -\underline{v}$, ovvero l'opposto di $\underline{v} \in V,\; \forall \underline{v} \in V$.
\end{itemize}
}

%@elia sarebbero da aggiungere gli esempi che non ho capito benissimo

\section{I Sottospazi Vettoriali}
Definiamo ora i sottospazi vettoriali:
\definizione{
    Sia $V$ uno spazio vettoriale su $K$ e $W\subset V$.
    Diremo che $W$ è un sottospazio vettoriale ($W<V$) di $V$ se:
    \begin{enumerate}
        \item $\underline{w}_1 + \underline{w}_2 \in W, \; \forall \underline{w}_1,\underline{w}_2 \in W$
        \item $\lambda \underline{w} \in W, \; \forall \underline{w} \in W$
    \end{enumerate}
}
\osservazione{se $W<V$, ovvero $W$ è sottospazio di $V$ allora $\underline{0}_V \in W$}

\paragraph{In parole povere} Se abbiamo uno spazio vettoriale $V$ e ne prendiamo un suo sottoinsieme $W$,
quest'ultima sarà anch'esso uno spazio vettoriale (sottospazio di $V$ in questo caso) soltanto se queste due proprietà vengono rispettate:
\begin{itemize}
    \item Se prendiamo qualunque coppia di elementi $w_1$ e $w_2$ in $W$, anche la loro somma deve far parte di $W$.
    \item se prendiamo un qualunque elemento $\underline{w}$ e un qualunque scalare $\lambda$, anche il loro prodotto deve far parte di $W$.
\end{itemize}
\osservazione{Lo spazio vettoriale piú semplice é quello che contiene solo l'elemento identitá ($\underline{0}$)}

\subsection[Sottospazi di R2]{I sottospazi vettoriali di $\R^2$}
Quali sono i sottospazi vettoriali di $\R^2$?
\\Innanzitutto ricordiamo che per fare si che un certo $W<\R^2$ ogni elemento deve rispettare le due condizioni di somma tra vettori e prodotto per uno scalare.
\\Detto ció, é dimostrabile che tutti i sottospazi vettoriali di $\R^2$ in ordine di grandezza sono:
\begin{itemize}
    \item $\{ \underline{0} \}$, ovvero l'insieme identitá.
    \item Tutte le \textbf{Rette passanti per l'origine}.
    \item ???
    \item $\R^2$ stesso.
\end{itemize}

\subsection{Il piú piccolo Sottospazio Vettoriale}
Dato $S\subset V$ con $V$ Spazio Vettoriale, esiste il piú piccolo sottospazio di $V$ contenente $S$?
Si, ed é definito cosí:
\definizione{
    $<S> < V$ Indica il piú piccolo sottospazio di $V$ contenente $S$.
    Si dimostra che:
    \[ <S> = \{ \sum_{i=1}^{n} \lambda_i \cdot z_i : \lambda_i \in \R, z_i \in S, n\in\N\} \]
}
Si osserva che non esiste $\sum_{i=1}^{\infty} \lambda_i \cdot z_i$, poiché la somma deve essere tra un \textbf{numero finito} di vettori.

\section{Combinazione Lineare}
La somma utilizzata nell'ultima definizione non é a caso, ma si chiama Combinazione Lineare:
\definizione{
    $\sum_{i=1}^{n} \lambda_i \cdot z_i$ si chiama \textbf{Combinazione Lineare} di $\{z_i\}_{i=1,...,n}$
}
\subsection*{Dipendenza Lineare}
Da qui possiamo andare a definire se i vettori di un insieme sono linearmente dipendenti o no:
\definizione{
    Sia $S\subset V$ con $V$ spazio Lineare.
    \\ I vettori di $S$ sono detti \textbf{Linearmente dipendenti} se:
    \begin{center}
        $\exists \underline{w} \in S$ e $S_{\underline{w}} = \{z_1,...,z_n\}\subset S$ (con $\underline{w} \notin S_{\underline{w}}$)
    \end{center}
    tali che
    \begin{center}
        \underline{w} = $\sum_{i=1}^{n} \lambda_i \cdot z_i, \lambda_i \in K$
    \end{center}
    Altrimenti, i vettori si $S$ sono detti \textbf{Linearmente Indipendenti} 
}
Ovvero, si dice che i vettori di un insieme sono linearmente dipendenti se sono la combinazione lineare di altri elementi dell'insieme.
\subsubsection*{Lemma}
$S\subset V$ é un insieme di vettori linearmente indipendenti sse:
\[ \sum_{i=1}^{n} \lambda_i \cdot z_i = \underline{0} \implies \lambda_i = 0 \forall i \]
Ció deve valere $\forall n \in N$ e $\forall \{z_i\} \subset S$.

\paragraph{Dimostrazione del Lemma}
$S\subset V$ è un insieme di vettori linearmente indipendenti.
Voglio dimostrare che se $\{\underline{z}_i \}<S$ e $\sum_{i=1}^{n} \lambda_i \underline{z}_i = \underline{0}$ allora $\lambda_i=0 \forall 0$.
\\Nego la tesi: Supponiamo che  $\sum_{i=1}^{n} \lambda_i \underline{z}_i = \underline{0}$ ma $\exists h : \lambda_h \neq 0$.
Allora 
\[\lambda_h z_h = -\sum_{j\neq h} \lambda_j \underline{z}_j \to ... \to z_h = -\sum_{j\neq h} \lambda_h^{-1} \lambda_j \underline{z}_j\]
Ovvero al combinazione lineare di vettori $\subset S$ diversi da $z_h$, quindi gli $\{\underline{z}_i \}$ sono linearmente dipendenti e lo sono anche quelli di $S$.

%Dimostrazione Inversa ed Esempi da aggiungere

\section{Basi}
Domanda: come "comunico" un sottospazio vettoriale?
\\Sia $W<V$, abbiamo 2 modi per "comunicarlo":
\begin{enumerate}
    \item Siccome $W\subset V$, allora $W=\{...\}$.
    \item Sfrutiamo il fatto che $W<V$ e quindi $<S>=W$ per qualche \underline{insieme} $S\subset V$,
    cerchiamo di "ottimizzare" $S$, ovvero cerchiamo il piú piccolo $S$ che rispetti $<S>=W$.
    \\Ció consiste nel determinare un S "minimale" tale che:
    \begin{center}
        $W = <S> =$ Spazio Vettoriale generato da S
    \end{center}
    La minimalitá é equivalente a:
    \[ W\neq <S/\underline{v}>, \; \forall \underline{v} \in S \]
\end{enumerate}

\definizione{
    Teorema/Definizione di Base: Tutte le seguenti affermazioni sono \textbf{equivalenti}:
    \begin{enumerate}[(a)]
        \item $S=\{\underline{v}_1,\underline{v}_2,...,\underline{v}_n\} \subset V$ é una Base di $V$.
        \item $S$ è un sistema di generatori per V, cioé $V=<S>$ e i vettori di $S$ sono linearmente indipendenti.
        \item $<S>=V$ e $\forall \underline{v} \in V, \exists ! \sum_{i=1}^{n} \lambda_i \underline{v}_i = \underline{v}$
        \item $S$ è un insieme minimale di generatori di $V$.
        \item $S$ è un insieme massimale di vettori linearmente dipendenti di $V$.
    \end{enumerate}
}
Come potrei dimostrare questo?
Essendo proposizioni equivalenti, avrò che:
\[ a \implies b, b\implies a, b \implies c, ... , e\implies d\]
Però posso semplicemente dimostrarne 5. %SPiegare
\paragraph{Corollario}\footnote{Conseguenza} Ogni spazio vettoriale che ammette un insieme finito di generatori ammette una base.

\esempio{
    (1) Abbiamo $V = \R^n$ e 
    \[ S= \{ (1,0,...,0), (0,1,0,...,0), ... (0,0,...,1)\} = \{ \underline{e}_1, \underline{e}_2, ... ,\underline{e}_n\}\]
    $S$ é detta \textbf{Base Canonica\footnote{Canonico non é ben definibile in matematica, è il suo nome di battesimo.}} di $\R^n$.
    \\Usiamo il teorema (c) per verificare che è una base:
    Sia $(x_0,x_2,...,x_n) = \sum_{i=1}^{n} \lambda_i \underline{e}_i = ... = (lambda_1,...,\lambda_n)$
    Quindi $\lambda_i = x_i$
    \\$\implies$ Tale combinazione lineare é \textbf{unica}, qiundi (c) é verificata e $S$ é una Base.
}

%TODO: sistemare questa parte
Uno dei teoremi più importanti per le basi è il teorema di \emph{estensione di una base}:
\paragraph{Teorema 2:}
Sia $I\{\underline{v}_1,...,\underline{v}_n\}$ insieme di vettori \textbf{Linearmente indipendenti} t.c. $I\subset V$,
e $G\{\underline{w}_1,...,\underline{w}_n\}$ insieme di \textbf{generatori} di $V$,
Allora $\exists G' \subset G : I \cup G'$ è una base di V.

\paragraph{Teorema 3:} Con le notazioni del teorema due, avremo che $\#(I) \leq \#(G)$, ovvero il numero di elementi di $I$ è minore o uguale al numero di elementi di $G$.

\paragraph{Corollario} del teorema 3:
Se $\exists G$ insieme finito t.c: è un sistema di generatori di $V$-spazio vettoriale, allora ogni base di $V$ ha lo stesso numero di elementi.
Ovvero fissato uno spazio, tutte le sue basi hanno lo stesso numero di elementi.

\definizione{
    La dimensione di uno spazio vettoriale $V$ che ammette un sistema di generatori finito è il numero di elementi di una base qualsiasi di $V$.
}
La dimensione comprende sia l'insieme che la struttura algebrica.

\paragraph{Corollario} $dim(V)=n\implies$ $n$ vettori indipendenti sono anche generatori.
Implica anche che $n$ generatori di $V$ sono linearmente indipendenti.