\chapter{Branch and Bound}
Il Branch and Bound è una tecnica per la risoluzione di problemi di ottimizzazione intera.
Questa è una tecnica di \emph{enumerazione implicita}, ovvero:
\begin{itemize}
    \item "Valuta" le soluzioni possibili fino a trovare quella ottima.
    \item Scarta alcune di queste soluzioni a priori dimostrando la loro non ottimalità.
    \item Si basa sul concetto di Dividi et Impera.
\end{itemize}  
\section{Come funziona}
Supponiamo di avere un problema di PLI che chiamiamo \emph{problema completo}.
\\Un problema di PLI rappresenta un \textbf{sotto-problema} del problema completo se presenta la medesima funzione obiettivo, ma ha un sottoinsieme proprio di $X$ come regione ammissibile.
\paragraph*{}Sia $z* = f(x*)$ la soluzione del problema completo e $\tilde{z} = f(\tilde{x}°)$ la soluzione ottima di un sotto-problema. Allora si ha che $f(\tilde{x}) \leq f(x*)$.
\\Basta solo notare che tra le soluzioni ammissibili del problema completo vi è anche $x$ (non dovrebbe essere $\tilde{x}$?) e che per definizione di ottimo $f(\tilde{x}) \leq f(x*)$.
\section{Le tecniche di risoluzione}
Il Branch and Bound fa uso delle tre seguenti tecniche per risolvere un generico problema di PLI:
\begin{itemize}
    \item La partizione rispetto al valore delle variabili, o \textbf{Branching}.
    \item La determinazione di un limite superiore, o \textbf{Bounding}.
    \item L'eliminazione di sottoproblemi, o \textbf{Fathoming}.
\end{itemize}
La procedura del Branch and Bound per i problemi di PB e quelli di PIM è molto simile, la soluzione dei problemi rilassati è ancora alla base delle fasi di \textit{bounding} e \textit{fathoming} ma occorre apportare alcune modifiche (che riporto nelle sezioni adeguate).
\subsection{Branching}
Il Branching implica la selezione di un sotto-problema da analizzare e la divisione di questo in sotto-problemi più piccoli. Vi sono diverse regole di selezione e divisione possibili. Posso scegliere:
\begin{itemize}
    \item \textbf{\textit{Il sotto-problema creato più di recente}}: tale regola di selezione è efficiente per ripartire con l'ottimizzazione del rilassamento LP dal precedente problema (devo solo aggiungere un vincolo). 
    \\\`E anche nota come \underline{\textit{Depth First}}, perché equivale a scegliere il nodo di livello maggiore, ovvero più profondo.
    \\\, \textopenbullet\ \underline{\textit{Pro}}: è semplice da implementare, permette di ottenere presto delle soluzioni ammissibili (ci si avvicina più rapidamente alle foglie) e limita la memoria necessaria per memorizzare l'albero delle soluzioni, visto che si tendono a chiudere molti nodi per inammissibilità e rimangono pochi nodi contemporaneamente aperti.
    \\\, \textopenbullet\ \underline{\textit{Cons}}: presenta il rischio di esplorare completamente sotto-alberi con soluzioni scadenti.

    \item \textbf{\textit{Il sotto-problema con il miglior bound}}: in genere conduce a soluzioni incombenti più velocemente e quindi permette di effettuare un \textit{fathoming} più efficiente.
    \\\`E anche nota come \underline{\textit{Best Bound First}}: si sceglie il nodo \textit{più promettente} ossia il nodo con il \textit{bound migliore} (\textbf{lower bound} più \textbf{basso}, per problemi di \textit{minimo}, o \textbf{upper bound} più \textbf{alto}, per problemi di \textit{massimo}).
    \\\, \textopenbullet\ \underline{\textit{Pro}}: permette di limitare il numero di nodi visitati esplicitamente e tende pertanto a essere più efficiente.
    \\\, \textopenbullet\ \underline{\textit{Cons}}: l'esplorazione tende a rimanere a livelli poco profondi, dove i problemi sono meno vincolati e i bound sono più promettenti ma difficilmente si ottengono presto soluzioni ammissibili che migliorino la soluzione incombente corrente. Questo impedisce di applicare efficacemente le regole di \textit{fathoming}, pertanto è maggiore la richiesta di memoria per i nodi aperti contemporaneamente.

    \item Si può anche usare una combinazione delle due regole: i nodi vengono scelti cioè alternando i diversi criteri, per evitare gli svantaggi di uno o dell'altro.
\end{itemize}

\subsubsection{Branching per problemi di PB (variabili binarie)}
Nel caso di problemi a variabili binarie (PB), il modo più semplice per dividere l'insieme delle soluzioni ammissibili in sotto-insiemi è fissare il valore di una delle variabili, per esempio $x_1 = 0$, per un sottoinsieme e a $x_1 = 1$ per l'altro sottoinsieme.\\
\begin{center}
    \includegraphics[width=0.5\textwidth]{img/B&B_PB1.jpg}
\end{center}
La variabile utilizzata ad ogni iterazione per eseguire questa suddivisione è chiamata \textbf{variabile di branching}. Nel diagramma qua sopra, al primo livello la variabile di branching sarà $x_1$, a quello successivo $x_2$ etc... Questo perché per selezionare ad ogni iterazione la variabile di branching si può utilizzare l'ordinamento naturale delle variabili ($x_1$, $x_2$, ...).
\\N.B.: nel caso binario, ad ogni branching generiamo due nuovi sotto-problemi, creando un albero binario.

\subsubsection{Branching per problemi di PIM }
Differisce dal \textit{Branching} per problemi di PB precedentemente visto per poche cose. Il \textbf{primo} cambiamento riguarda la scelta della variabile di \textit{Branching}:
\begin{itemize}
    \item Nel B\&B per PB la scelta è stata effettuata seguendo l'indice delle variabili: ora non è più possibile perché sulle variabili continue non può essere effettuato il \textit{Branching}.
    \item La regola deve essere modificata scegliendo la prima variabile non continua seguendo l'ordine naturale degli indici (o regole più sofisticate).
\end{itemize}
Il \textbf{secondo} cambiamento riguarda i valori assegnati alla variabile per generare i sotto-problemi:
\begin{itemize}
    \item Nel caso PB alla variabile di branching veniva assegnato il valore 0 e 1 rispettivamente per generare i due nuovi sotto-problemi.
    \item Nel caso generale, assegnare tutti i possibili valori interi sarebbe impossibile quindi si generano due sotto-problemi specificando per la variabile due insiemi di valori $$x_j\, \le\, \lfloor x_j^* \rfloor\quad e\quad x_j\, \ge\, \lfloor x_j^* \rfloor\, +\, 1$$ dove $\lfloor x_j^* \rfloor$ è il massimo intero per cui $\lfloor x_j^* \rfloor\, \le\, x_j^*$.
\end{itemize}
N.B.: può verificarsi che una stessa variabile venga selezionata più volte durante la procedura.
\\Il \textbf{terzo} cambiamento riguarda la fase di \textit{Bounding}.
\\Il \textbf{quarto} (e ultimo) cambiamento riguarda la fase di \textit{Fanthoming}.

\subsection{Bounding}
\subsubsection{Bounding per problemi di PB (variabili binarie)}
Per ognuno dei sotto-problemi dobbiamo ricavare un limite superiore (perché è un problema di massimo, altrimenti un limite inferiore).
\\Per ottenere questo limite si risolve il \textit{problema rilassato} (ovvero senza considerare i vincoli di interezza ma, essendo il problema binario, limitando le variabili tra 0 e 1).
\\Quindi risolvo i miei sotto-problemi sostituendo l'ultima riga con i vincoli $x_j \ge 0 \wedge x_j \le 1$ (ovvero $0 \le x_j \le 1$).
\\Come prima cosa risolviamo la versione rilassata del problema completo (per esempio con il metodo del simplesso) e otteniamo un valore per la nostra $Z$, per esempio $Z = 12,345$. Essendo nell'ambito binario possiamo (come anche nell'ambito intero ovviamente) arrotondare, in questo caso all'intero precedente: se i coefficienti della funzione obiettivo del problema sono tutti interi e le soluzioni del problema devono essere binarie (o intere), sicuramente con le mie variabili non potrei mai raggiungere il valore decimale.

\subsubsection{Bounding per problemi di PIM}
\begin{itemize}
    \item Nel caso PB, se i coefficienti della funzione obiettivo erano tutti interi, il valore della soluzione del problema rilassato $Z$ poteva essere arrotondato all'intero inferiore (se \textit{Max}, viceversa se \textit{Min}).
    \item Nel caso generale questo non è più possibile.
\end{itemize}

\subsection{Fathoming}
\subsubsection{Fathoming per problemi di PB (variabili binarie)}
Un sotto-problema può essere "eliminato" dalla lista dei problemi da considerare per tre possibili ragioni: 
\begin{enumerate}
    \item La soluzione ottenuta soddisfa i vincoli di interezza (come la soluzione del sotto-problema 1. In particolare, questa soluzione può essere considerata come la soluzione intera migliore trovata fino a questo momento (soluzione incombente Z*). Quindi il valore della soluzione incombente a questo punto è Z*=9).
    \\La soluzione incombente cambierà ogni volta che un sotto-problema otterrà una soluzione intera migliore della soluzione incombente corrente.
    \item La soluzione incombente può essere utilizzata per un'altra possibilità di fathoming: se il bound di un sotto-problema (che rappresenta la soluzione ottima migliore che si potrà trovare continuando a considerare il sotto-problema) è peggiore della soluzione incombente (migliore soluzione ammissibile intera già trovata) allora non vale la pena continuare a considerare il sotto-problema che quindi può essere chiuso (\textit{fathomed}).
    \item Il sotto-problema non ammette soluzioni ammissibili.
\end{enumerate}
Quindi verranno ulteriormente risolti ed analizzati solo quei problemi che non hanno una soluzione intera ma il loro bound è migliore della soluzione incombente.

\subsubsection{Fanthoming per problemi di PIM}
\begin{itemize}
    \item Nel caso PB, potevamo fermarci se la soluzione del problema era \textit{intera}.
    \item Nel caso generale basta che la soluzione soddisfi la condizione di interezza per le variabili che non possono essere continue.
\end{itemize}

\section{La divisione di una variabile}
Può essere effettuata in più modi:
\begin{itemize}
    \item si sceglie una variabile e si assegnano valori diversi (es.: programmazione binaria);
    \item si assegna alla variabile un insieme di valori (es.: problemi di PLI).
\end{itemize}
\subsubsection{Branching} 
La scelta della variabile su cui effettuare il \textbf{branching} va effettuata tra eventuali possibili scelte con l'obiettivo di arrivare più velocemente ad una possibilità di \textit{fathoming}.
\subsubsection{Bounding} 
Il \textbf{bounding} è generalmente eseguito risolvendo un rilassamento del problema (noi ne abbiamo visto un tipo, ma ne esistono varie tipologie).

\section{Il rilassamento Lagrangiano}
L'intero insieme di vincoli funzionali $\mathbf{Ax\, \le\, b}$ viene \textit{cancellato} (o \textit{quasi interamente cancellato}) e la funzione obiettivo $$Max\ Z\, =\, \mathbf{cx}$$ viene sostituita da $$Max\ Z\, =\, \mathbf{cx\, -\, \lambda(Ax - b)}$$
Il problema $$Max\ Z\, =\, \mathbf{cx\, -\, \lambda(Ax - b)}$$ $$\,\quad s.t.\ \ge\: 0$$ è detto \textbf{\textit{problema Lagrangiano}} e ha la proprietà secondo la quale $\forall\, \lambda\, \ge\, 0$ fissato la sua soluzione ottima costituisce un \textbf{upper bound} sull'ottimo del problema originario di \textit{Max} (\textbf{lower bound} se il problema è di \textit{Min}).
\\Il bound ottenibile con il \textit{rilassamento Lagrangiano} è quindi almeno tanto buono quanto quello ottenibile con il \textit{rilassamento lineare}.
\subsubsection{Pro}
L'efficacia pratica del rilassamento Lagrangiano è legata all'\underline{efficienza} con cui si riesce a \underline{risolvere il problema duale} del problema Lagrangiano.
\subsubsection{Cons}
Non è però efficiente come il rilassamento LP nel calcolare il \textit{primo} e il \textit{terzo} dei test di \textit{fathoming}.
\subsubsection{I criteri di Fanthoming}
Ricordando che i criteri di \textit{fathoming} derivanti dall'\underline{analisi di un problema rilassato}:
\begin{itemize}
    \item \textit{Criterio 1}: \`E stata trovata una soluzione ottima intera del sotto-problema.
    \item \textit{Criterio 2}: La soluzione ottima $Z$ del sotto-problema deve essere peggiore della soluzione incombente $Z^*$ ($Z\, \le\, Z^*$ per un problema di \textit{Max} e \textit{viceversa} per un problema di \textit{Min}).
    \item \textit{Criterio 3}: Il sotto-problema non presenta soluzioni ammissibili.
\end{itemize}

\section{Problemi con soluzioni ottime alternative}
Potrebbe essere importante poter ottenere una lista delle soluzioni ottime, in modo che la scelta della soluzione migliore possa essere poi effettuata sulla base di considerazioni che potrebbero non essere state incluse nel modello matematico.
\\Per trovarle basta fare alcune piccole modifiche:
\begin{itemize}
    \item Il test del Criterio 2 deve essere fatto sulla base della disugualianza stretta ($Z\, <\, Z^*$ per un problema di \textit{Max} e \textit{viceversa} per un problema di \textit{Min}).
    \\In questo modo il \textit{Fanthoming} non avverrà se $Z\, =\, Z^*$.
    \item Se la soluzione di un sotto-problema soddisfa il criterio 1 con $Z\, =\, Z^*$ allora anche questa soluzione deve essere memorizzata come incombente, e occorre controllare se il sotto-problema ammette soluzioni multiple. Nel qual caso occorre calcolare e memorizzare anche le soluzioni alternative come incombenti.
\end{itemize}
Alla fine della procedura tutte le soluzioni correnti incombenti (tutte \textit{equivalenti}) saranno considerate \textbf{ottime}.

\section{Soluzioni "quasi-ottime"}
Il Branch and Bound può essere utilizzato anche per trovare soluzioni "buone" (quasi-ottime) anche se non necessariamente ottime, che in genere richiedono uno sforzo computazionale molto minore.
\\Una soluzione è considerata quasi-ottima quando la sua soluzione $Z$ è "abbastanza" vicina al valore di una soluzione ottima $Z^{**}$, ovvero $$Z^{**} -\, K \le Z$$ o equivalentemente $$(1\, -\, \alpha)Z^{**} \le\, Z$$ dove $K$ e $\alpha$ sono costanti date.
\\N.B.: $\alpha$ mi rappresenta l'approssimazione (percentuale) della soluzione quasi-ottima trovata.
\\Quindi se una soluzione incombente $Z^*$ soddisfa $$Z^{**} -\, K \le Z^*$$ oppure $$(1\, -\, \alpha)Z^{**} \le\, Z^*$$ 
\\La procedura può terminare fornendo una soluzione $Z^*$ quasi-ottima.
\\
\\Ma come si può identificare quel valore $Z^{**}$?
\\Se esistesse una soluzione ammissibile con valore $Z^{**}$ allora si avrebbe $Z^{**} \le\, Bound$ dove $Bound$ è la soluzione migliore tra quelle dei problemi rilassati ancora aperti.
\\Quindi possiamo sostituire $Bound$ a $Z^{**}$ nelle formule precedenti ottenendo: $$Bound\, -\, K \le Z^*$$ oppure $$(1\, -\, \alpha)Bound\, \le\, Z^*$$
\\Anche se la soluzione corrispondente a $Bound$ non è ammissibile (intera) costituisce comunque un limite superiore valido.
\\Per problemi di grosse dimensioni considerare le soluzioni quasi-ottime può evitare tempi computazionali proibitivi.

\section{Criteri d'arresto}
Il metodo del Branch-and-Bound si arresta quando tutti i nodi sono dichiarati \textit{fathomed}. In questo caso, la soluzione ammissibile corrente corrisponde ad una soluzione ottima.
\\Si possono anche usare soluzioni quasi-ottime e fermarci non appena troviamo una soluzione quasi ottima. 
\\Oppure ancora possono anche essere adottati criteri relativi a limiti computazionali, come ad esempio raggiunti limiti di tempo di calcolo o di memoria, ma non è garantito che l'eventuale soluzione ammissibile corrente sia ottima (posso comunque calcolare quanto distante è dal $Bound$).

\section{Considerazioni finali sul B\&B}
\subsubsection{Valutazione di soluzioni ammissibili}
Per applicare efficacemente le regole di \textit{Fathoming}, è necessario disporre di soluzioni ammissibili di buona qualità. Bisogna quindi stabilire come e quando calcolare soluzioni ammissibili.
\\Abbiamo varie possibilità:
\begin{itemize}
    \item Aspettare che l'enumerazione generi un nodo foglia ammissibile;
    \item Implementare un algoritmo che valuti una buona soluzione prima dell'esplorazione;
    \item Sfruttare, con frequenza da valutare, l'informazione raccolta durante l'esplorazione dell'albero per costruire soluzioni ammissibili sempre migliori;
    \item In ogni caso, bisogna \textbf{sempre} valutare il compromesso tra la qualità della soluzione ammissibile corrente e lo sforzo computazionale per ottenerla.
\end{itemize}