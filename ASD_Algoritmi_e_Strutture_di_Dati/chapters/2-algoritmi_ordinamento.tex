\chapter{Algoritmi di ordinamento}
In questo capitolo vedremo algoritmi di ordinamento, più che per la loro
funzione primaria, per studiare come è possibile affrontare un problema con diverse
tecniche e come l'utilizzo di diverse tecniche influenzi anche notevolmente l'efficienza.
\section{Selection Sort}
Ordinamento per selezione, dove per selezione intendo che ad ogni passo seleziono
il valore minimo presente nell'array, scambio l'elemento più piccolo con l'elemento in
prima posizione, mi sposto sul secondo valore e cerco il più piccolo, andrà a sostituirlo
nella seconda posizione, e così via fino a quando non ho un solo valore da ordinare.\\
Qui di seguito il codice:
\begin{lstlisting}[language=Java]
void SelSort(int A[])
  (n-1)+1  For i = 1 to length(A) - 1
  (n-1)       Pmin = i
  sum(n-i)         For j = i + 1 to length(A)
  sum(n-i)              if A[j] < A[Pmin]
  t-if                      Pmin = j
  //Variabile appoggio per lo scambio
  (n-1)            app = A[i] 
  (n-1)            A[i] = A[Pmin]
  (n-1)            A[Pmin] = app
\end{lstlisting}
Length(A) - 1, perchè l'ultimo valore sono sicuro che sarà il più grande di tutti
dato che per gli tutti gli altri elementi ho cercato il minimo.\\
\paragraph*{Tempo esecuzione} Il For viene eseguito (n-1)+1 volte perchè devo
considerare anche il controllo finale che viene effettuato.\\
Il secondo For invece è più complesso da gestire perchè dipende anche da i che è esterna
al ciclo stesso. Ogni volta che eseguo il secondo For l'array si restringe di 1 perchè ogni
volta ordino un valore (trovando il minimo) quindi avrò una progressione del tipo $(n + (n-1) +
(n-2) + (n-3) + \dots + (1))$, quindi $(n-i) + 1 $, devo considerare perchè che verrà eseguito
ogni volta che il primo For viene eseguito quindi $\sum_{i=1}^{n-1}(n-i)$.\\
Il tempo di esecuzione sarà quindi:
\begin{equation*}
    5(n-1) + 2\sum{i=1}^{n-1} (n-1) + t_{if}
\end{equation*}
Dove 5(n-1) e la sommatoria non dipendono dall'input, mentre $t_if$ sì.
\paragraph*{Ricerca e Analisi caso peggiore} Il caso peggiore è A ordinato al contrario,
dato che in questo caso l'if viene eseguito ogni volta (dato che A[j] sarà sempre minore di A[Pmin]).\\
$t_if$ avrà il seguente tempo di esecuzione $(n-1)+(n-2)+(n-3) + \dots + 1 = \sum_{i=1}^{n-1} = \sum_{i=1}^{n}i$\\
Quindi:
\begin{equation*}
    T_p(n) = 5(n-1) + 3\sum_{i=1}^{n-1}(n-1) = 5(n-1) + 3\sum_{i=1}^{n}i
\end{equation*}
Ricordiamo questa equivalenza:
\begin{equation*}
    \sum_{i=1}^{f}i = \frac{f(f+1)}{2}
\end{equation*}
Quindi sostituendo otteniamo:
\begin{equation*}
    5(n-1)+3\frac{(n-1)n}{2}
\end{equation*}
Dato che a noi interessa l'ordine di grandezza e non ci interessano i dettagli possiamo approssimare questo
risultato come:
\begin{equation*}
    \approx 5n + n^2 \approx n^2
\end{equation*}
\paragraph*{Nota} In realtà se è decrescente quando scambio il minimo in fondo all'array con il primo valore,
che sarà il maggiore, sta ordinando entrambi gli elementi, però per semplificazione consideriamo che
l'if viene eseguito ogni volta.
\paragraph*{Ricerca e Analisi caso migliore}
Il caso migliore è quando l'array è ordinato dato che non eseguo mai l'if, quindi dato che
$t_{if} = 0$ ottengo:
\begin{equation*}
    t_m(n) = 5(n-1) + 2 \sum_{i=1}^{n-1}(n-1)+0 = 5(n-1) + \frac{2}{2}(n-1)n = 5n +n^2\\
    \approx n^2
\end{equation*}
Notiamo quindi che il caso migliore e peggiore non sono molto diversi, anzi hanno lo stesso
ordine di grandezza.

\section*{Insertion Sort}
In questo caso ordino partendo dal primo numero e controllando il secondo, verifico se il primo
è maggiore del secondo e nel caso li scambio, poi controllo il terzo numero e procedo a ordinarlo
insieme a primi due e così via.
\paragraph*{Esempio} \'E come ordinare un mazzo di carte pescandole mano, quindi inizialmente ho due
carte, le ordino confrontandole ed eventualmente scambiandole, poi pesco la terza e la ordino
con le altre due e così via, fino a quando non ho pescato tutte le carte.
\subsection{Implementazione}
\begin{lstlisting}[language=Java]
    void InsSort(A[])
(n-1)c  For i = 2 to length(A)
(n-1)c      App = A[i]
(n-1)c      j = j - 1
sum(tw)     while App < A[j] AND j > 0
sum(tw)         A[j+1] = A[j]
sum(tw)         j--
(n-1)c      A[j+1] = App
\end{lstlisting}
Uso il For perchè in ogni caso devo ordinare tutti i numeri dell'array, parto da
2 perchè un numero da solo è ordinato, quindi è inutile analizzarlo, inoltre j sarebbe uguale a 0,
e noi partiamo a contare da 1 gli indici dell'array.\\
\subsection{Tempi d'esecuzione, caso migliore e peggiore}
\paragraph*{Tempo di esecuzione} Faremo alcune approssimazioni dato che cerchiamo l'ordine
di grandezza dei tempi di esecuzione:
\begin{itemize}
    \item Non consideriamo l'ultima istruzione di controllo del For (quella che ci fa uscire dal ciclo)
    \item Non considero neanche l'ultima istruzione di controllo del While
\end{itemize}
Il For quindi richiederà n-1 istruzioni, dove \textbf{c} è un generico tempo di esecuzione per ogni istruzione,
dato che parte da 2 e non da 1.\\
Il while non ha un numero di volte fisso per cui è vero, dipende dall'input! Ci sarà un caso
peggiore e uno migliore, scrivo quindi $\sum_{i=2}^n{t_w}$ per indicare il numero di volte in cui il While è vero, 
la sommatoria è inserita perchè devo sommare tutte le esecuzioni While per ogni i-esima esecuzione 
del ciclo For.\\
Qui di seguito la spiegazione della sommatoria
\begin{align*}
    tw_{i=2} + tw_{i=3} + tw_{i=4} + \dots + tw_{i=n} \\
    \sum_{i=2}^n{tw_i}
\end{align*}
Il tempo di esecuzione è quindi
\begin{equation*}
    t_{is}(n) = 4c(n-1)+3c \sum_{i=2}^n tw_i
\end{equation*}
Dato che non è possibile definire in maniera univoca il numero di volte in cui
il while verrà eseguito andiamo a determinare il caso migliore e quello peggiore.
\paragraph*{Caso migliore} Il vettore è già ordinato. Analizzando il codice dobbiamo
verificare cosa può cambiare, in questo caso il While, quindi qual è il caso dove
il while viene eseguito meno volte? Quando App $<$ A[j] sempre, quindi $tw_i = 0$ 
per ogni i e questo accade quando A[] è già ordinato.
\begin{equation*}
    t_m(n) = 4c(n-1)+3c*0=4c(n-1)
\end{equation*}
\paragraph*{Caso peggiore} Il while viene eseguito il maggior numero di volte per ogni
i, cioè $tw_i=j=i-1$. Questo si verifica quando A è ordinato al contrario.\\
\begin{equation*}
    T_p(n) = 4c(n-1)+3c \sum_{i=2}^n (i-1)
\end{equation*}
Converto la sommatoria
\begin{equation*}
    \sum_{i=2}^n i-1 = 1+2+3+\dots+(n-1) = \sum_{i=1}^{n-1}i = \frac{(n-1)n}{2}
\end{equation*}
Inserisco nella formula
\begin{equation*}
    4c(n-1)+3c \frac{(n-1)n}{2} \approx 4cn+3c \frac{n^2}{2} \approx n^2
\end{equation*}
\paragraph*{Approssimazione caso migliore} Il caso migliore lo posso approssimare come n.
\subsection{Confronto tra Selection e Insertion sort}
Grazie alle approssimazioni possiamo confrontare i due algoritmi e notiamo subito che
il caso migliore di Insertion è migliore di Selection Sort dato che è nel primo caso è n,
mentre nel secondo è $n^2$.\\
Insertion Sort è quindi migliore di Selection Sort.
\section{Nozioni per rappresentare i tempi di esecuzione}
\begin{equation*}
    T(n) = O(n^2)
\end{equation*}
O (o grande) indica il limite asintotico superiore del tempo di esecuzione (il caso peggiore),
in altre parole indica il tempo massimo che posso aspettare per ricevere il risultato.\\
Mentre:
\begin{equation*}
    t(n) = \Omega(n)
\end{equation*}
Indica il limite inferiore del tempo di esecuzione (il caso migliore), quindi il tempo
minimo che devo aspettare.\\
Nei casi dove questi due casi corrispondono si indicano con:
\begin{equation*}
    \Theta(n^2)
\end{equation*}
$\Theta$ indica che il tempo è uguale (approssimativamente) per tutti gli input.
\subsection{Limiti asintotici}
I limiti asintotici sono delle funzioni per cui sono sicuro che la funzione presa in
considerazione $f(n)$ è sempre minore del limiti asintotico. In questo caso
dico che la funzione è asintoticamente limitata $f(n) = O(n^2)$.
%Riprendere spiegazione teoria dato che è una possibile domanda d'esame
Le lettere O, $\Omega$, $\Theta$, indicano una costante moltiplicativa per cui posso
moltiplicare la funzione e trova una funziona per la quale la mia funzione n non sarà
mai maggiore (nel caso di O), o minore (nel caso di $\Omega$) della funzione che la limita
asintoticamente. Questa costante indica tutto ciò che ho trascurato nel calcolo dei tempi, 
posso sceglierla a piacere per verificare che la funzione non violerà mia i limiti
asintotici. (FORMALIZZARE QUESTA PARTE AGGIUNGENDO FORMULE - GUARDA APPUNTI IPAD)
\begin{align*}
    O(g(n)) = \{f(n):\exists k>0, n_0 \geq 0 \,\, \text{t.c}\,\, \\
    0 \leq f(n) \leq k*g(n), \forall n \geq n_0 \}
\end{align*}
Questo ci porterà a fare delle approssimazioni come per esempio non considerare
l'ultimo controllo del for o del while, questo produrrà delle situazioni che possono
sembrare non sensate, per esempio potrà risultare che la condizione del while non viene mai
eseguita, in realtà non è vero, perchè almeno 1 volta verrà eseguito, però per le approssimazioni
che abbiamo scelto di fare non lo consideriamo.
\paragraph*{Attenzione}
\begin{enumerate}
    \item Devo scegliere la funzione che solo per alcune costanti sia più grande/piccola di quella confrontata
    ($\exists k \,\, \text(t.c)$),
    altrimenti sto scegliendo un o (o-piccolo) dove la funzione è grande/piccola per ogni costante scelta
    ($\forall$).
    \item Non mi interessa se il il termine di ordine maggiore sia seguito da addizioni o sottrazioni
    \item Di fronte a un tempo costante come $\Omega$ indichiamo 1
\end{enumerate}
\subsection{Proprietà}
O, $\Omega$, $Theta$ hanno le seguenti proprietà:
\begin{itemize}
    \item Sono Transitivi
    \item Simmetria vale solo per $\Theta$
    \item Simmetria trasposta per O e $\Omega$ - Es. $2n = O(n^2) \,\, n^2=\Omega(2n)$
\end{itemize}

\section{Esercizio ricerca elementi V2 in V1}
\paragraph*{Richiesta} Dati 2 vettori V1 e V2, con n valori interni, quanti elementi di
V2 compaiono in V1? Valutare quindi i tempi di esecuzione dell'algoritmo.
\paragraph*{Osservazioni} Dati i seguenti due vettori
\begin{center}
    V1 = (7, 4, 4, 4, 12)\\
    V2 = (3, 7, 4, 15, 20)
\end{center}
Gli elementi di V2 che compaiono in V1 sono 2, il 4 non devo contarlo più volte!\\
Viceversa, se ci fosse stato il 4 più volte in V2 e anche 1 sola volta in V1, andava contato
più volte.
\subsection{Implementazione}
\begin{lstlisting}[language=Java]
    int confronta(V1[], V2[])
c*1        cont = 0
c*n        for i=0 to length(V2)
c*n            j=1
sum(c*twi)     while (V2[i] != V1[j]) AND j <= length(V1)
sum(c*twi)        j++;
c*n            if j <= length(V1)
c*tif             cont++
c*1        Return(cont)
\end{lstlisting}
Dove sum(c*twi) sarebbe $\sum_{i=1}^n{c*tw_i}$\\
\paragraph*{Tempo algoritmo}
\begin{equation*}
    2c*1 + 3c*n + c*t_if + 2c \sum_{i=1}^n{tw_i}
\end{equation*}
Posso portare fuori la c e il 2 dalla sommatoria dato che sono 2 costanti.
\paragraph*{Ricerca caso peggiore}
Analizzo le due istruzioni variabili, cioè
\begin{itemize}
    \item if
    \item while
\end{itemize}
Quale pesa di più? Il controllo dell'if viene eseguito ogni volta, l'incremento del conteggio non sempre, però conta comunque
1 istruzione, e comunque l'if viene sempre eseguito, mentre il while può essere rieseguito
diverse volte, questo mi suggerisce che devo cercare un caso dove
il while viene eseguito molte volte, dato che è potenzialmente molto più pesante dell'if.\\
In generale ci capiteranno sempre 2 quantità in contrasto, come in questo caso abbiamo l'if e il while, dovremo
determinare la quantità più pesante.\\
Il caso peggiore è quindi quello in cui il while cicla il maggior numero di volte possibile, quando $tw_i$ è max per
ogni i, quindi quando nessun elemento di V2 è presente in V1.\\
\paragraph*{Tempo}
\begin{align*}
    tw_1=n, \,\, tw_2=n \,\, \dots tw_n=n\\
    T_p(n) = 2c+3c*n+c*t_if+2c\sum_{i=1}^n{n}\\
    =2c+3c*n+0+2cn^2
\end{align*}
Perchè $\sum_{i=1}^n{n}=n+n+n+n+n ... \,\, \text{per n volte } = n^2$\\
Da questo risultato mi rendo conto che l'ordine di grandezza è $n^2$, per esprimerlo
in maniera formale scrivo:
\begin{align*}
    = O(n^2)
\end{align*}
\paragraph*{Ricerca caso migliore}
Il caso migliore è quello dove il while non viene mai eseguito (0 esecuzioni del while
ad ogni iterazione del for).\\
Il caso migliore NON è i 2 array sono uguali, perchè ci saranno delle iterazioni in cui il while verrà
eseguito, il caso migliore è quando V2 contiene un solo elemento ripetuto n volte e lo stesso
elemento è presente in V1[1].
\begin{center}
    V1 1,2,3,4\\
    V2 1,1,1,1
\end{center}
\paragraph*{Tempo}
\begin{align*}
    tw_i = 0 \quad \forall i \rightarrow t_if = n\\
    t_m(n) = 2c + 3cn + cn + 2c \sum_{i=1}^n {0}\\
    =\Omega(n)
\end{align*}
In questo caso (opposto al precedente) while non viene mai eseguito e if n volte.\\
