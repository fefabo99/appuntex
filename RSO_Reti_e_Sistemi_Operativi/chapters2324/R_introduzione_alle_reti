\chapter{Introduzione alle reti}
\section{Cos'è Internet?}
Due prospettive:
\begin{itemize}
    \item Visione degli ingranaggi (dadi e bulloni), delle componenti della rete.
    \item Visione della rete come un'infrastruttura che fornisce servizi.
\end{itemize}
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/R_introduzioneallereti1.jpg}
\end{center}
Nell'immagine che schematizza, sui bordi della rete troviamo un grandissimo numero di devices (cell, laptops, \dots) che eseguono \textit{applicazioni di rete} che richiedono uno scambio di dati e che la rete si occupa di collegare. Alcuni nodi di questa applicazione eseguono parte di un'applicazione e altri nodi interconnessi eseguono altre parti di applicazioni (sistemi distribuiti).

\subsection{Visione nuts and bolts}
\begin{description}
    \item[hosts:] dispositivi \textit{end system} ovvero terminali.
    \item[packet switches] o \textit{commutatori di pacchetto}\textbf{:} sono \textit{routers} e \textit{switches}, dispositivi che si occupano di trasferire pacchetti (unità) di informazione.\\
    I pacchetti sono unità in cui l'informazione viene scomposta ed etichettata per essere trasferita da un dispositivo all'altro.
    \item[Communication links] o \textit{collegamenti di comunicazione}\textbf{:} sono i canali che collegano i nodi della rete. Li disegnamo come righe che uniscono i vari nodi. Possiamo crearli usando diversi mezzi trasmissivi, filo di rame, onde radio, fibra ottica\dots Ognuno di questi link è definito da una \textbf{banda}, la quantità di informazione che il link può trasferire in un secondo.
    \item[Networks:] Internet è una rete di reti, ovvero una rete di dispositivi che sono collegati tra loro e che a loro volta sono reti di dispositivi collegati tra loro. Quindi tutta la rete è una connessione globale di reti locali (es. la rete dell'ufficio, la rete domestica\dots)
\end{description}
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_introduzioneallereti1.jpg}
\end{center}
Sempre più dispositivi oggi giorno si sono evoluti fino ad adattarsi all'uso di Internet, come ad esempio le auto, i frigoriferi, le lavatrici\dots 
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_introduzioneallereti2.jpg}
\end{center}
Quindi anche Internet deve evolversi e adattarsi per poter gestire un numero sempre maggiore di dispositivi con esigenze sempre più diverse.

\subsubsection{Internet come rete di reti}
Abbiamo detto che Internet è viibile appunto come una rete di reti, un \textit{insieme interconnesso} di \textbf{ISPs} (Internet Service Providers), le organizzazioni che gestiscono la rete. A volte ISPs viene usato anche come sinonimo della rete vera e propria.\\
Gli ISPs comunicano fra loro tramite l'uso di \textbf{protocolli}. I protocolli nella rete sono ovunque, controllano il modo in cui i messaggi vengono inviati e ricevuti tra i dispositivi. Alcuni esempi sono HTTP (Web), streaming video, Skype, TCP, IP, WiFi, 4G, Ethernet\dots\\
Questi protocolli si basano su \textbf{standards}.\\
Un lavoro fondamentale a riguardo è svolto da \textbf{enti di standardizzazione} (il più famoso è IETF, \textit{Internet Engineering Task Force}) che stilano documenti (RFC, \textit{Request for Comments}) che spiegano come i protocolli devono essere implementati e come i dispositivi che implementano questi protocolli devono comportarsi.\\
Gli standard sono fondamentali per la comunicazione univoca tra i dispositivi, senza di essi non ci sarebbe interoperabilità tra i dispositivi.

\subsection{Visione come infrastruttura di servizi}
Internet può essere visto come un'\textbf{infrastruttura} che fornisce \textbf{servizi} alle applicazioni distribuite.\\
\`E una vista importante perché la rete sottostante è fondamentale per quando dobbiamo per esempio programmare delle applicazioni o dei servizi: da questo pov è molto importante il concetto di socket, un'interfaccia che ci permette di interfacciarci alla rete senza necessariamente sapere come la rete sotto funziona.

\section{Protocolli}
\subsection{Cos'è un protocollo?}
\begin{center}
    \quad \textbf{\underline{Protocolli umani} \quad \underline{Protocolli di rete}}
\end{center}
\parbox{0.5\textwidth}{
% \textbf{Protocolli umani}\\
I protocolli umani sono le regole che seguono gli esseri umani quando comunicano tra loro.\\
Es.: incontro una persona, scambio di convenevoli, poi chiedo: "Che ore sono?" e in base alla risposta ho delle reazioni diverse.\\
Altro es.: "Ho una domanda" durante una lezione, così che per non interrompere il professore, lui possa finire il suo discorso e poi rispondere alla domanda.\\
Altro es.: un giro di tavolo per fare le presentazioni, seguo delle convenzioni di discorso.}
\hfill
\parbox{0.4\textwidth}{
% \textbf{Protocolli di rete}\\
Emulano il funzionamento dei protocolli umani.\\
Tutte le comunicazioni di rete sono gestite da protocolli.\\
\\ 
\\ 
\\ 
\\ 
\\ 
\\ 
\\ 
\\ 
\\ 
}
\definizione{I \underline{protocolli di rete} definiscono le regole per i messaggi inviati in rete. In particolare definiscono il \textit{formato dei messaggi}, \textit{l'ordine} in cui vengono \textit{inviati} e \textit{ricevuti} tra le entità di rete (host, commutatori, \dots) e le \textit{azioni da intraprendere} una volta che questi messaggi vengono inviati e ricevuti.}
\begin{center}
    \includegraphics[width=0.625\textwidth]{images/aa2324/R_introduzioneallereti3.jpg}
\end{center}

\section{Da cosa è composta la rete?}
Andiamo più nel dettaglio.
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/R_introduzioneallereti4.jpg}
\end{center}
\subsubsection{Network edge}
Primo segmento della struttura generale della rete. Ci troviamo sui bordi della rete (quindi c'è un po' una diatriba sul fatto che appartengano o meno alla rete, in ogni caso sono molto importanti), dove si trovano gli \textbf{hosts} (client, server). Sono intesi in senso un po' lato, ovvero:
\begin{itemize}
    \item I \textit{client} sono intesi come dispositivi con una \textit{bassa} capacità computazionale.
    \item I \textit{server} sono intesi come dispositivi con una \textit{alta} capacità computazionale.\\
    Infatti di solito si trovano nei data center.
\end{itemize}

\subsubsection{Access networks}
Addentrandoci ancora più nella rete, abbiamo le reti di accesso. Tipicamente hanno dei collegamenti di comunicazione che possono essere \textit{wired} (cavi, stoppini, fibre \dots) e \textit{wireless} (4G, onde radio\dots). Sono molto importanti perché accolgono il traffico dagli utenti e lo portano verso la rete. O viceversa accolgono il traffico di dati da passare al client. Per accedere alla rete bisogna acquistare un accesso alla rete per mezzo di un provider, un ISP.\\
Sono importanti perché evolvono molto rapidamente nel tempo, sostengono sempre più il cambiamento e l'evoluzione del traffico generato dagli utenti a loro volta in costante evoluzione.\\
Non parleremo delle reti di accesso.

\subsubsection{Network core}
La rete di core è una rete con una maglia di dispositivi solitamente molto performanti (quindi in grado di gestire una gran quantità di informazione) e che si trovano al centro della rete. Permettono di implementare quella rete di reti di cui abbiamo parlato prima.\\
Per mezzo delle reti di core garantisco che ogni utente che si trova in rete possa comunicare con ogni altro utente che si trova nella stessa rete. Ovviamente non è sempre concretamente possibile.\\
Internet è una rete connessa: da un nodo posso raggiungere un qualsiasi altro nodo. Questo è quello di cui si occupano le reti core: permettono di mettere in comunicazione reti più al limitare della rete di altre.

\subsection{Network edge}
L'host, abbiamo detto, ha il compito di inviare pacchetti di dati, prende un messaggio applicativo che deve inviare e lo scompone in pacchetti di lunghezza pari ad $L$ (per semplicità ora li consideriamo tutti della stessa lunghezza, ma di solito hanno dimensioni di lunghezza variabile). Questi pacchetti vengono inviati dall'host in rete dalle reti di accesso che forniscono l'accesso ad un rate trasmissivo (banda, capacità\dots) pari a $R$ (è in bit/s). Questo vuol dire che l'host può inviare pacchetti di lunghezza $L$ a velocità $R$.
\begin{center}
    \textit{Ovviamente più è alta la banda, più è alta la velocità di trasmissione.}
\end{center}
Ma come si calcola il \textbf{ritardo di trasmissione}?
\definizione{Il \textit{ritardo di trasmissione} è il ritardo che intercorre tra l'invio del primo bit di un pacchetto di $L$ bit alla ricezione dall'altro lato del link dell'ultimo bit dello stesso pacchetto.}
Essendo $L$ la lunghezza del pacchetto e $R$ la velocità di trasmissione, il \textit{ritardo di trasmissione} sarà pari a $L/R$.
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_introduzioneallereti5.jpg}
\end{center}

\subsection{Access networks}
Abbiamo detto che Internet è un \textit{packet switching network}, una rete a commutazione di pacchetto. L'unità informativa che viene scambiata in rete è il \textbf{pacchetto} che appunto viaggiano in rete, ricevuti e trasmessi da più dispositivi.\\
Il compito della rete è di inoltrare i pacchetti verso i router o i commutatori di pacchetto sul link corretto che va da sorgente a destinazione. Questo è il compito principale dei dispositivi della rete di core: creare un percorso (possibilmente il migliore) fra sorgente e destinazione.\\
Sembra, almeno concettualmente, abbastanza banale come concetto. Ma la gerarchia della rete è studiata in modo che nodi sufficientemente vicini possano essere messi in contatto senza passare da router o commutatori.
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_introduzioneallereti6.jpg}
\end{center}

\subsection{Network core}
Come sono fatti i nodi della rete di core:
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_introduzioneallereti7.jpg}
\end{center}
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_introduzioneallereti8.jpg}
\end{center}
\begin{description}
    \item[Forwarding table:] è una tabella che contiene le intestazioni dei vari pacchetti (dove c'è specificato l'indirizzo della destinazione e quale interfaccia ovvero l'uscita del link da cui il pacchetto deve uscire) da inviare verso una specifica interfaccia.\\
    L'\textbf{inoltro} (forwarding) ha ovviamente valenza locale. Ogni singolo nodo consultando la propria tabella prende decisioni autonome riguardo l'inoltro.
    \item[Switching:] \textbf{commutazione}, sinonimo di inoltro (forwarding). Le due terminologie hanno una valenza simile ma si riferiscono a due cose leggermente diverse: l'\textit{inoltro} è l'operazione di \underline{ricevere un messaggio e inoltrarlo} verso un altro nodo, mentre la \textit{commutazione} è l'operazione per \underline{trasferire il} \underline{pacchetto} da un'interfaccia di ingresso ad una di uscita di un router.\\
    Il risultato è lo stesso, ma lo \textit{switching} è più \underline{a livello interno del nodo} ignorando ciò che sta all'esterno, il \textit{forwarding} invece tiene in considerazione che io prendo e inoltro \underline{da un nodo} un pacchetto che sposto poi attraverso 1+ link \underline{ad un altro nodo}.
    \item[Routering:] ogni singolo nodo prende decisioni localmente, ma io devo garantire che una volta che diversi nodi effettuano l'operazione di inoltro in serie il pacchetto arrivi da sorgente a destinazione senza intoppi. Parliamo di \textbf{routing}, instradamento, azione \textbf{globale} che ha l'obiettivo di trovare un percorso tra sorgente che invia il pacchetto a destinazione che lo riceve. In ognuno dei nodi avremo un \textbf{algoritmo di routing} che agisce in maniera distribuita; un algoritmo di routing comunica con un altro algoritmo di routing tramite protocolli di routing che permettono di popolare la \textbf{tabella di forwarding} in maniera corretta. 
\end{description}

\section{Modalità packet-switching}
\subsection{Store-and-forward}
La rete internet abbiamo detto essere a commutazione di pacchetto e opera secondo la modalità store-and-forward.

\subsubsection{Cos'è lo store-and-forward?}
\`E quella modalità per cui un pacchetto prima di poter essere inviato attraverso un link (ad esempio verso un router), deve essere prima inviato nella sua interezza dal nodo da cui arriva. Questo è dovuto al fatto che ogni pacchetto è dotato di un'intestazione che se persa mi fa perdere anche informazione su cosa sia quel pacchetto.\\
Nell'immagine abbiamo una sorgente, un commutatore e una destinazione.
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_packetswitching1.jpg}
\end{center}
Se per dire inviassi un bit al commutatore e lui lo spedisse verso la destinazione senza aspettare il resto del pacchetto dalla sorgente, se il bit si perdesse non saprei a chi quel bit appartiene.

\subsubsection{Perché lo store-and-forward è importante?}
La modalità store-and-forward è importante quindi perché semplifica notevolmente come le reti debbano essere costruite, prima di inviare un pacchetto devo riceverlo tutto, ricostruirlo, e analizzare l'intestazione per sapere cosa contiene e che è legata a quello specifico pacchetto.

\subsubsection{Problemi dello store-and-forward}
\textit{Introduce dei ritardi}, ovviamente, dovendo aspettare che un pacchetto sia ricevuto per intero prima di poterlo inoltrare. Questo ritardo vale $2\frac{L}{R}$ secondi a trasmettere attraverso un link un pacchetto di $L$ bits ad una velocità $R$ di trasmissione. Questo perché impiega $\frac{L}{R}$ secondi per trasmettere il pacchetto al commutatore e altri $\frac{L}{R}$ secondi per trasmettere il pacchetto dal commutatore alla destinazione.\\
Se invece non usassi questa modalità e ad esempio facessi passare un bit alla volta attraverso il commutatore, impiegherei meno tempo: agirebbe come se il commutatore non esistesse e i due link di velocità $R$ fossero direttamente collegati tra loro, come un unico link più lungo, quindi la velocità complessiva sarebbe comunque $R$ e il tempo di trasmissione \textbf{totale} sarebbe $\frac{L}{R}$ secondi. Ovviamente avrei meno ritardi ma altri problemi che vedremo in seguito.

\subsection{Esempio di esercizio}
\begin{center}
    \includegraphics[width=0.50\textwidth]{images/aa2324/R_packetswitching1.jpg}
\end{center}
Se come in figura avessi tre pacchetti alla sorgente in attesa di essere inviati (P1, P2 e P3), quanto tempo (in multipli di $\frac{L}{R}$) passerebbe fra l'invio dalla sorgente del primo bit di P1 alla ricezione della destinazione dell'ultimo bit di P3?\\
La risposta è $4\frac{L}{R}$. Perché?
\begin{enumerate}
    \item P1 viene inviato al commutatore in $\frac{L}{R}$ secondi.
    \item P1 viene inviato alla destinazione e P2 viene inviato al commutatore in $\frac{L}{R}$ secondi.
    \item P2 viene inviato alla destinazione e P3 viene inviato al commutatore in $\frac{L}{R}$ secondi.
    \item P3 viene inviato alla destinazione in $\frac{L}{R}$ secondi.
\end{enumerate}

\subsection{Queueing}
Abbiamo parlato di possibili problemi riscontrabili con lo store-and-forward. Uno dei principali svantaggi è che in una rete a commutazione di pacchetto si verifica quello che si chiama \textbf{accodamento di pacchetti} o \textbf{queueing}.
\begin{center}
    \includegraphics[width=0.50\textwidth]{images/aa2324/R_packetswitching2.jpg}
\end{center}
Nella maggior parte dei casi quello che può verificarsi è che il rate a cui io posso trasmettere in uscita sul mio link è più basso rispetto a quello con cui ricevo i pacchetti. Nell'immagine ho un $R$ pari a $100\nicefrac{Mb}{s}$ sui link in ingresso e un $R$ pari a $1.5\nicefrac{Mb}{s}$ sui link in uscita, \textit{molto} più basso. Arriverò ad un punto in cui non riesco a smaltire i miei pacchetti che si accumulano sul router ad un ritmo sufficientemente sostenuto da tenere il passo del ritmo con cui li ricevo. Allora comninciano ad accumularsi in \textit{buffer}, in zone di memoria, e si crea una coda di pacchetti in attesa di essere trasmessi sul link in uscita.\\
Queste zone di memoria del commutatore hanno però una capacità limitata (ovviamente) e quando il rate del link in uscita è troppo inferiore rispetto al rate in ingresso al commutatore e quindi si accumulano i pacchetti, rischio di andare in \textbf{\textit{buffer} overflow}: è rischioso perché quando lo raggiungo poi perdo i pacchetti che incuranti continuano ad arrivare, e che vengono scartati.\\
Questo problema è chiamato \textbf{il problema della perdita nelle reti a commutazione di pacchetto}.\\
Un altro problema è il \textbf{ritardo di accodamento}.

\subsection{Alternativa alla modalità packet-switching: circuit-switching}
Una rete a commutazione di circuito si basava su principi molto diversi da quelli visti finora.\\
Al giorno d'oggi non è più usata, ma è importante conoscerla perché è stata la prima modalità di funzionamento delle reti di telecomunicazione. Un esempio è la vecchia rete telefonica (fissa di casa).\\
Si hanno delle risorse dedicate esclusivamente alla chiamata o al circuito, quando si stabilisce una chiamata si stabilisce un circuito dedicato che rimane dedicato per tutta la durata della chiamata. Una certa quantità di banda viene riservata esclusivamente alla comunicazione: stabilendo un circuito end-to-end di risorse dedicate alla comunicazione.
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_circuitswitching1.jpg}
\end{center}
\begin{description}
    \item[Vantaggi:] non ho i problemi tipo l'accodamento, non ho ritardi di accodamento, non ho perdita di pacchetti. Quindi migliori prestazioni.
    \item[Svantaggi:] scarsa capacità, ho per esempio nell'immagine un numero massimo di 4 dispositivi collegabili. Quindi peggior utilizzo e scarsa condivisione delle risorse.
\end{description}

\subsection{Packet-switching vs circuit-switching}
Boh non c'è tanto da scrivere, spesso diceva che non lo vediamo nel corso quindi salterei.

\section{Struttura della rete: reti di reti}
Abbiamo detto che gli \textit{hosts} sono connessi da \textit{links} e \textit{ISPs}.\\
Come più volte abbiamo visto, la rete ha una struttura di tipo \textbf{gerarchico}: diversi provider forniscono connettività di tipi diversi. Ci sono nel mondo milioni di reti che fanno da punto di accesso a diversi clients/hosts, e devono essere connesse tra loro.

\subsubsection{Prima ipotesi}
Creare un punto di accesso verso tutte le altre reti di accesso. Non è affatto fattibile!! Non scala: il numero di collegamenti diretti che io dovrei avere fra le reti di accesso è dell'ordine di $O(n^2)$.

\subsubsection{Seconda ipotesi}
Creare un rete di un ISP che connette tutte le reti di accesso. Questo è quello che succede oggi giorno. Si interconnette a tutte le reti di accesso e grazie ad una rete di commutatori permette la commutazione fra tutte quelle reti di accesso.\\
Si crea una rete in cui ogni rete di accesso paga l'ISP per poter avere l'accesso ed essere messo in comunicazione con tutte le altre.

\subsection{Problemi e soluzioni}
Una rete così fatta dovrebbe essere geometricamente estesissima, e questo non è fattibile. Si va quindi a creare una rete di reti di ISP, geometricamente più limitate ma anche numerose. Così una rete può scegliere da chi comprare l'accesso.\\
Il problema che sorge ora è che se una rete di ISP non è in comunicazione con un'altra rete di ISP, come faccio a mettere in comunicazione due reti di accesso che sono collegate a due reti di ISP diverse?\\ 
Si vanno a creare allora dei link che le mettano in comunicazione, collegamenti:
\begin{description}
    \item[peering link:] link fra pari, tra un ISP di una rete di ISP e un altro di un'altra rete.\\
    Vantaggioso ad entrambi.\\
    Due tipi diversi:
    \begin{description}
        \item[regional ISP:] collegamento fra \textbf{una} ISP e diverse reti di accesso a cui fornisce accesso.
        \item[Multi-homing:] collegamento fra \textbf{diverse} ISP e diverse reti di accesso a cui fornisce accesso, migliore perché nel caso cada la connessione con un ISP ci sono gli altri a mantenere attiva la connessione.         
    \end{description}
    \item[IXP:] internet exchange point, interconnessioni fra ISP di reti diverse. Punti di contatto fra diversi ISPs.\\
    Il MIX è quello di Milano e il più importante d'Italia.
    \item[Content provider network:] esempio Google, straordinariamente geograficamente estesa in modo da prendere quanti più ISPs possibili. Ha un vantaggio per tutti, comprese le reti di accesso, hanno tutti accessi privilegiati.
\end{description}

\subsection{Ritardi introdotti dalla packet-switching}
\textbf{4} tipi diversi di ritardo:
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/R_packetswitching3.jpg}
\end{center}
Il ritardo di queueing è l'unico che può variare notevolmente da pacchetto a pacchetto. Gli altri sono (all'incirca) costanti per pacchetti diversi. Uno che non abbiamo visto è il \textbf{ritardo di elaborazione al nodo}. Ritardo introdotto dal commutatore per effettuare alcune operazioni, tra cui la lettura della tabella di inoltro (\textit{look up} la \textit{table}) per recuperare le informazioni sul link di output. Ogni volta che un pacchetto arriva al commutatore, il commutatore deve analizzare l'intestazione del pacchetto per capire se ci sono stati problemi di trasmissione. Ci sono tutti dei codici/meccanismi per controllare ed eventualmente correggere questi eventuali errori (se non li correggo rischio di perdere il pacchetto, se li correggo lo posso salvare). Questo prende tempo, che diventa il \textbf{ritardo di elaborazione ($d_{proc}$)}, questo tempo è dell'ordine di grandezza di $10^{-9}$ secondi. Un altro dato decisamente più importante (2-3 ordini di grandezza più grande, $10^{-6} - 10^{-3}$ secondi) è il \textbf{ritardo di accodamento ($d_{queue}$)}. L'abbiamo già visto. \`E il tempo che un pacchetto aspetta sul mezzo di trasmissione di uscita (cavo) prima di essere trasmesso, dipende dal livello di congestione del router. Poi abbiamo il \textbf{ritardo di trasmissione ($d_{trans} = \nicefrac{L}{R}$)}, anche questo già visto, che dipende dalla lunghezza del pacchetto ($L, bits$) e velocità di trasmissione ($R, bps$). Poi abbiamo il \textbf{ritardo di propagazione ($d_{prop} = \nicefrac{d}{s}$)} tempo che un pacchetto impiega praticamente a fluire da un'estremità all'altra del pacchetto. Dipende dal mezzo di trasmissione, quindi lunghezza del cavo ($d$) e velocità di propagazione ($s$, circa pari alla velocità della luce, $\sim 2 \times 10^8 \frac{m}{sec}$).\\
A sommare tutte queste componenti, ottengo il tempo complessivo che il pacchetto ci mette a passare da sorgente a destinazione.
\subsubsection{Recap:}
\begin{center}
    \begin{tabular}{ |c|c|c| } 
        \hline
        Nome del ritardo & Sigla & Tempo \\
        \hline
        \hline
        R. di elaborazione & $d_{proc}$ & $10^{-9}$ sec \\ [0.75ex] 
        R. di accodamento & $d_{queue}$ & $10^{-6} - 10^{-3}$ sec \\ [0.75ex] 
        R. di trasmissione & $d_{trans}$ & $\nicefrac{L}{R}$ \\ [0.75ex] 
        R. di propagazione & $d_{prop}$ & $\nicefrac{d}{s}$ \\ [0.75ex] 
        \hline
    \end{tabular}
\end{center}
Dove:
\begin{center}
    \begin{tabular}{ |l l l| } 
        \hline
        $\mathbf{L}$: & lunghezza del pacchetto & [$bit$]\\ [0.75ex]
        $\mathbf{R}$: & velocità di trasmissione & [$\nicefrac{bit}{sec}$]\\ [0.75ex]
        $\mathbf{d}$: & lunghezza del mezzo & [$m$]\\ [0.75ex]
        $\mathbf{s}$: & velocità di propagazione & [$\nicefrac{m}{sec}$] = $\sim 2 \times 10^8 \nicefrac{m}{sec}$\\ [0.75ex]
        \hline
    \end{tabular}
\end{center}

Una cosa fondamentale è la differenza fra \textit{ritardo di trasmissione} e \textit{ritardo di propagazione}: entrambi dipendono dal mezzo su cui il pacchetto viene trasferito, ma sono diversi. Il primo dipende dalla dimensione del pacchetto e il rate di trasmissione del commutatore; il secondo dalla lunghezza del mezzo propagativo (cavo, fibra ottica, whatever) e la sua capacità di propagazione, che è una velocità ma non la stessa dell'altro ritardo.
\subsubsection{Es.}
Immaginiamo di essere in tangenziale. Arrivo alla barriera e mi fermo al casello di boh Sesto, poi devo arrivare alla barriera di Legnano. Immaginiamo di avere un certo numero di macchine (i bit) che fanno parte di uno stesso pacchetto.\\
Per semplicità un solo casello. La differenza fra r. di trasmissione e r. di propagazione è: mettiamo di avere un casellante che fa passare 4 macchine al minuto, che portano ad un ritardo di trasmissione $R_T$ (che ovviamente diminuisce all'aumentare della capacità del trasmittente). Se il casellante si sbriga, passano più macchine (più bit al minuto) e quindi il ritardo di trasmissione è più basso. Ovviamente c'è un limite fisico di velocità. Una volta che il casellante mi fa passare, io devo percorrere la tangenziale fino al casello successivo, che è un ritardo di propagazione $R_P$ che dipende dalla lunghezza della tangenziale e dalla velocità massima che posso raggiungere.

\subsection{Ritardo \textit{end-to-end}}
\`E il ritardo che intercorre per il processing fra sorgente e destinazione, introdotto da tutti i commutatori di pacchetto fra uno e l'altro e i ritardi introdotti dai sistemi periferici.\\
Abbiamo detto che è la somma delle 4 sorgenti di ritardo: $d_{nodal} = d_{proc} + d_{queue} + d_{trans} + d_{prop}$.\\
Quando parliamo di \textit{ping} però facciamo riferimento al tempo che ci mette un pacchetto a passare da sorgente a destinazione e di nuovo indietro da destinazione alla sorgente, prende il nome di ritardo \textit{round-trip-time}.

\subsection{Di più sul ritardo di queueing}
Il ritardo di queueing cambia da pacchetto a pacchetto.\\
Nel caso più generico possibile dipende dal tasso di \textbf{intensità di traffico}. Come si calcola? Con strumenti statistici. Abbiamo un rate medio di arrivo dei bit ($\bar{a}$), le lunghezze dei pacchetti ($L$) e la velocità di trasmissione del mezzo ($R$).\\
L'intensità di traffico è definita come $\nicefrac{L \centerdot \bar{a}}{R}$.\\
Se l'intensità di traffico tende a 0, allora il ritardo di queueing tende ad essere molto piccolo.\\
Se l'intensità di traffico tende a 1, allora il ritardo di queueing tende ad essere larghino.\\
Se l'intensità di traffico è maggiore di 1, allora il ritardo di queueing tende a infinito ed è ingestibile.\\
N.B.: stiamo parlando di valori medi!!!

\subsection{Perdita di pacchetti}
Più cause:
\begin{itemize}
    \item capacità del commutatore satura (buffer overflow) che porta alla perdita di pacchetti inviati dopo che la capacità finita è stata riempita.
    \item problemi sul mezzo trasmissivo
\end{itemize}
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/R_packetswitching4.jpg}
\end{center}
I pacchetti con errori di trasmissione vengono scartati. Potrebbe succedere che in qualche modo si è perso il pacchetto e decidere di ri-inviarlo ma non è scontato.

\subsection{Throughput}
Calcolato come una velocità, rate (bits/time unit) a cui i bits sono inviati da sorgente a destinazione (a volte chiamato \textbf{\textit{end-to-end throughput}}, anche se questi due termini sono abbastanza simili e quindi possono essere usati singolarmente) ed è:
\begin{description}
    \item[istantaneo:] rate ad un certo punto dato nel tempo
    \item[medio:] rate in un periodo più esteso di tempo
\end{description}
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/R_packetswitching5.jpg}
\end{center}
Domande:
\begin{description}
    \item[$R_s < R_c$:] quale è il throughput medio?\\
    $R_s$ perché il rate di trasmissione è più basso del rate di ricezione.\\
    In questo caso non c'è accodamento sul commutatore.
    \item[$R_s > R_c$:] quale è il throughput medio?\\
    $R_c$ perché il rate di trasmissione è più alto del rate di ricezione.\\
    In questo caso c'è accodamento sul commutatore.
\end{description}
Parliamo di \textbf{\textit{bottleneck link}}, che è quel link sul percorso tra sorgente e destinazione (ovvero il percorso end-to-end) che vincola il throughput end-end. Nel primo caso è $R_s$, nel secondo è $R_c$.

\subsubsection{Throughput: network scenario}
\begin{center}
    \includegraphics[width=50mm]{images/aa2324/R_packetswitching6.jpg}
\end{center}
Mettiamo di avere una rete come nella situazione in immagine. Abbiamo un certo numero (qua 10) di server, sopra nell'immagine, che acquistano un accesso alla rete per mezzo di un provider di una rete di accesso e hanno quindi link con velocità $R_s$. Immaginiamo vogliano comunicare con i client (diciamo ancora 10) che si trovano in basso, e che hanno accesso alla rete per mezzo di altri link con dimensione $R_c$.\\
Immaginiamo ora di modellare la rete di core come un link di dimensione $R$ (oppure, posso dire che nella rete di core ho un link di dimensione $R$ condiviso da tutte le connessioni in modo \textbf{fair}, ovvero equamente, quindi con rate $\nicefrac{R}{10}$). Il throughput sarà dato dal minimo fra questi, ovvero $min(R_c, R_s, \nicefrac{R}{10})$.\\
Difficilmente $\nicefrac{R}{10}$ sarà il bottleneck link: è decisamente sottodimensionato rispetto agli altri, tipicamente il bottleneck link sarà $R_c$ o $R_s$.