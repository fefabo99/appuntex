% 47:00 lezione 04/10/2023
\chapter{Processi e Threads}
Vedremo sostanzialmente come i s.o. gestiscono \textbf{processi} e \textbf{thread} e cosa si intende con questi due termini.
\section{Argomenti}
\begin{itemize}
    \item Concetto di processo, operazioni e API POSIX
    \item Comunicazione interprocesso e le API POSIX
    \item Multithreading e le API POSIX
\end{itemize}

\section{Concetto di \textit{processo}}
\subsection{Cos'è un processo}
Un s.o. ha come obiettivo il fatto di prendere un sistema di elaborazione e fare in modo che su di esso possano essere eseguiti più programmi in modo concorrente. Il loro numero può essere arbitrariamente elevato, di solito molto maggiore del numero di processori, di CPU del sistema. Il s.o. ci permette però di eseguire il n° di programmi che vogliamo indipendentemente dal n° di CPU che abbiamo. Come?\\
\textit{Il s.o. realizza e mette a disposizione una macchina astratta, un'astrazione detta \textbf{processo}}.\\
\definizione{Un \textbf{processo} è un'entità attiva astratta definita dal sistema operativo allo scopo di eseguire un programma.}
All'interno del s.o. il processo è l'unità esecutiva del programma. Es.: su un pc da 4 CPU, 50 programmi in esecuzione vuole dire 50 processi.\\
Supporremo \textbf{per ora} che l'esecuzione di un processo sia \textbf{sequenziale} e quindi \textit{non ci sia concorrenza}.

\subsection{Programmi e processi}
Notare la differenza tra \textit{programma} e \textit{processo}!
\begin{itemize}
    \item Un \underline{programma} è un'\underline{entità passiva} (un insieme di istruzioni, tipicamente contenuto in un file sorgente o eseguibile)
    \item Un \underline{processo} è un'\underline{entità attiva} (è un \textit{esecutore di un programma}, o un \textit{programma in esecuzione})
\end{itemize}
Uno \textit{stesso programma} può dare origine a \textit{diversi processi}:
\begin{itemize}
    \item \underline{Diversi utenti} eseguono lo \underline{stesso programma}
    \item Uno \underline{stesso programma} viene eseguito \underline{più volte}, anche contemporaneamente, dallo \underline{stesso utente}
\end{itemize}

% \subsection{\textit{Multiprogrammazione} e \textit{multitasking}}
% Obiettivi del sistema operativo:
% \begin{itemize}
%     \item Mantenere impegnata la (o le) CPU il maggior tempo possibile nell'esecuzione dei programmi (se ci sono programmi da eseguire)
%     \item Dare l'illusione che ogni processo abbia una CPU dedicata
% \end{itemize}
% Due tecniche adottate nei sistemi operativi sono la \textbf{multiprogrammazione} e il \textbf{multitasking} (o \textbf{time-sharing}, sono sinonimi):
% \begin{description}
%     \item[Obiettivo della multiprogrammazione:] impedire che un programma che non è in condizione di proseguire l'esecuzione mantenga la CPU
%     \item[Obiettivo del multitasking:] far sì che un programma interattivo reagisca agli input utente in un tempo accettabile (è una tecnica \textbf{non} rilevante per i sistemi puramente \textit{batch}, ma lo è principalmente per i programmi interattivi, che continuano a prendere dati dall'utente che li usa)
% \end{description}

% \subsubsection{Multiprogrammazione: l'implementazione}
% Il sistema operativo mantiene in memoria i processi da eseguire.\\
% Quando una CPU non è impegnata ad eseguire un processo, il sistema operativo seleziona un processo non in esecuzione e gli assegna la CPU.\\
% Quando un processo non può proseguire l'esecuzione (ad es. perché deve attendere il termine dell'input di dati che gli servono per proseguire), la sua CPU viene assegnata ad un altro processo non in esecuzione.\\
% Come risultato, se i programmi da eseguire sono più delle CPU, queste saranno impegnate nell'esecuzione di qualche processo per la maggior parte del tempo. Questo risolve il problema dell'efficienza: \textit{non tenere le CPU ferme}.

% \subsubsection{Multiprogrammazione: la memoria}
% La multiprogrammazione richiede che tutte le immagini di tutti i processi siano in memoria perché questi possano essere eseguibili.\\
% Se i processi sono troppi non possono essere contenuti tutti in memoria: la tecnica dello \textbf{swapping} può essere usata per spostare le immagini dentro/fuori dalla memoria. 
% \begin{wrapfigure}{r}{0.2\textwidth}
%     \begin{center}
%         \includegraphics[width=0.2\textwidth]{images/aa2324/SO_multiprogrammazione1.jpg}
%     \end{center}
% \end{wrapfigure}
% \definizione{\textbf{Swapping} significa che il s.o. può togliere la memoria (anche detta \textit{immagine}) di un processo dalla memoria centrale e caricare l'immagine di un altro processo.}
% La memoria virtuale è un'ulteriore tecnica che permette di eseguire un processo la cui immagine non è completamente in memoria.\\
% Queste tecniche aumentano il numero di processi che possono essere eseguiti in multiprogrammazione, ossia il grado di multiprogrammazione.\\
% Es.: se in un istante sto eseguendo 100 processi, il grado di multiprogrammazione è 100. Se in un altro istante sto eseguendo 50 processi, in quell'istante il grado di multiprogrammazione sarà 50.

% \subsubsection{Multitasking: l'implementazione}
% \`E un'\textit{estensione della multiprogrammazione} per i \underline{sistemi interattivi}.\\
% La CPU viene "sottratta" \underline{periodicamente} al programma in esecuzione ed assegnata ad un altro programma. Quindi non più solo quando il programma non è più in grado di proseguire ma anche ogni tot, così tutti i programmi hanno la possibilità di progredire. In questo modo tutti i programmi progrediscono in maniera continuativa nella propria esecuzione, anziché solo nei momenti in cui il programma che detiene la CPU si mette in attesa.\\
% Questo permette che i programmi batch, che effettuano poco I/O (e quindi vanno poco in attesa), non monopolizzino la CPU a discapito dei programmi interattivi.

\subsection{Struttura di un processo}
Un processo è composto da diverse parti:
\begin{itemize}
    \item Lo stato dei registri del processore che esegue il programma, incluso il program counter.
    \item Lo stato della regione di memoria centrale usata dal programma, o \textbf{immagine} del processo.
    \item Lo stato del processo stesso.
    \item Le risorse del sistema operativo in uso al programma (files, semafori, regioni di memoria condivisa\dots).
\end{itemize}
\textit{Processi distinti} hanno \textit{immagini distinte} (\textit{isolamento dei processi}).\\
Le risorse del sistema operativo invece possono essere condivise tra processi (a seconda del tipo di risorsa).

\subsubsection{Immagine di un processo}
L'intervallo di indirizzi di memoria \textit{\texttt{min\dots max}} in cui è contenuta l'immagine di un processo è anche detto \textbf{spazio di indirizzamento} (\textit{address space}) del processo. Ovviamente ogni processo lavora nel proprio spazio di indirizzamento.
\begin{wrapfigure}{r}{0.25\textwidth}
    \centering
    \includegraphics[width=.25\textwidth]{images/aa2324/SO_implementazioneprocessi1.jpg}
\end{wrapfigure}
L'immagine di un processo è formata da:
\begin{itemize}
    \item Lo \textbf{stack} delle chiamate, contenente parametri, variabili locali e indirizzo di ritorno delle varie procedure che vengono invocate durante l'esecuzione del programma.
    \item Lo \textbf{heap}, contenente la memoria allocata dinamicamente durante l'esecuzione.
    \item La \textbf{data section}, contenente le variabili globali.
    \item La (\textbf{text section}) contiene il codice macchina del programma.
\end{itemize}
\textit{Text} e \textit{data section} hanno dimensioni costanti per tutta la vita del processo.\\
\textit{Stack} e \textit{heap} invece crescono/decrescono durante la vita del processo, smetteranno solo quando una delle due sezioni raggiungerà la fine della memoria allocata per il processo, ovvero collidono tra loro.

\section{Operazioni sui processi}
I sistemi operativi di solito forniscono delle chiamate di sistema con le quali un processo può creare/terminare/manipolare altri processi.\\
Dal momento che \emph{solo un processo può creare un altro processo}, all'avvio il sistema operativo crea dei processi "primordiali" dai quali tutti i processi utente e di sistema vengono progressivamente creati.\\
Vedremo ora le operazioni fondamentali per:
\begin{itemize}
    \item Creare processi
    \item Terminare processi
\end{itemize}

\subsection{Creazione di processi}
Chi crea il primo processo? Il s.o., in fase di booth. Il fatto che un processo crei un altro processo dà origine ad una \textbf{gerarchia}. Di solito nei sistemi operativi i processi sono organizzati in maniera gerarchica.\\
Un processo (padre ) può creare altri processi (figli). Questi a loro volta possono essere padri di altri processi figli, creando un albero di processi.\\
Un albero di processi in Linux:
\begin{center}
    \includegraphics[width=0.50\textwidth]{images/aa2324/SO_operazioniprocessi1.jpg}
\end{center}
La relazione padre/figlio è di norma importante per le politiche di condivisione risorse e di coordinazione tra processi.\\
Possibili politiche di condivisione di risorse:
\begin{itemize}
    \item Padre e figlio condividono tutte le risorse (\textbf{non} l'immagine, abbiamo detto che ogni processo ha la propria immagine) \dots 
    \item \dots o un opportuno sottoinsieme \dots 
    \item \dots o nessuna
\end{itemize}
Possibili politiche di creazione spazio di memoria/indirizzi:
\begin{itemize}
    \item Il figlio è un duplicato del padre (stessa memoria e programma) \dots 
    \item \dots oppure no, e bisogna specificare quale programma deve eseguire il figlio\\
    Questo succede per le API Posix e non per le Win32.
\end{itemize}
Possibili politiche di coordinazione padre/figli:
\begin{itemize}
    \item Il padre è sospeso finché i figli non terminano \dots 
    \item \dots oppure eseguono in maniera concorrente
\end{itemize}

\subsection{Terminazione di processi}
I processi di regola richiedono esplicitamente la propria terminazione al sistema operativo (ovvero invoca una API che di solito si chiama \texttt{exit}).\\
Un processo padre può attendere o meno la terminazione di un figlio.\\
Un processo padre può forzare la terminazione di un figlio. \`E sempre brutto terminare forzatamente un processo (facendolo quindi terminare in maniera asincrona, senza avere quindi il tempo di fare operazioni per uno shut-down ordinato) piuttosto che lasciarlo terminare spontaneamente, ma a volte si rende necessario. Possibili ragioni:
\begin{itemize}
    \item Il figlio sta usando risorse in eccesso (tempo, memoria\dots).
    \item Le funzionalità del figlio non sono più richieste (ma è meglio terminarlo in maniera "ordinata" tramite IPC).
    \item Il padre termina prima che il figlio termini (in alcuni sistemi operativi).
\end{itemize}
Riguardo all'ultimo punto, alcuni sistemi operativi non permettono ai processi figli di esistere dopo la terminazione del padre:
\begin{itemize}
    \item \textbf{Terminazione in cascata:} anche i nipoti, pronipoti\dots\, devono essere terminati (non c'è nelle API Posix).
    \item La terminazione viene iniziata dal sistema operativo.
\end{itemize}

\subsubsection{API Posix per operazioni sui processi:}
\begin{description}
    \item[\texttt{fork()}] crea un nuovo processo figlio; il figlio è un duplicato del padre ed esegue \underline{concorrentemente} ad esso, ritorna al padre un \underline{numero identificatore (PID)} \underline{del processo figlio} e al figlio (che così capisce di essere il figlio) il PID 0.
    \item[\texttt{exec()}] sostituisce il programma in esecuzione da un processo con un altro programma, che viene eseguito dall'inizio; viene \underline{tipicamente usata dopo una} \underline{\texttt{fork()}} dal figlio per iniziare ad eseguire un programma diverso da quello del padre.
    \item[\texttt{wait()}] viene chiamata dal \underline{padre} per attendere la fine dell'esecuzione di un figlio (qualsiasi); ritorna:
    \begin{itemize}
        \item Il PID del figlio che è terminato.
        \item Il codice di ritorno del figlio (passato come parametro alla \texttt{exit()}).
    \end{itemize}
    \item[\texttt{exit()}] fa terminare il processo che la invoca:
    \begin{itemize}
        \item Accetta come parametro un codice di ritorno numerico che dice come è andata\\
        (es. tipicamente se il figlio ritorna 0 allora è terminato normalmente, se invece è un numero $\neq 0$ c'è un errore di qualche tipo e il padre deve essere in grado di capire e gestire il codice di errore).
        \item Il sistema operativo elimina il processo e recupera le sue risorse.
        \item Quindi restituisce al processo padre il codice di ritorno (se ha invocato \texttt{wait()}, altrimenti lo memorizza per quando l'invocherà).
        \item Viene implicitamente invocata se il processo esce dalla funzione \texttt{main}.
    \end{itemize}
    \item[\texttt{abort()}] fa terminare forzatamente un processo figlio.
\end{description}
La sequenza \texttt{fork-exec} nelle API POSIX:
\begin{center}
    \includegraphics[width=0.90\textwidth]{images/aa2324/SO_operazioniprocessi2.jpg}
\end{center}

\subsection{Processi \textit{zombie} e \textit{orfani}}
Ricordiamo che abbiamo detto che nelle API Posix non c'è la terminazione a cascata.
\begin{description}
    \item[P. zombie:] Se un processo termina ma il suo padre non lo sta aspettando (non ha invocato \texttt{wait()}) il processo è detto essere \textbf{\textit{zombie}}. Praticamente il processo ritorna un codice di errore ma non c'è nessuno a prendere e gestire il codice di errore. Il processo viene allora riallocato ma il codice rimane, quindi il processo non è effettivamente morto. Per questo \textit{zombie}.
    \item[P. orfano:] Se un processo padre termina \underline{prima} di un suo figlio, il figlio è detto essere \textbf{\textit{orfano}} (non vi è terminazione a cascata).
\end{description}

\section{Comunicazione interprocesso}
N.B.: quello di cui abbiamo parlato finora non vuol dire "$1$ processo $= 1$ applicazione". Es. Chrome, con più tab, \textbf{non} è un processo solo, \textit{ogni} tab è un processo. Questo perché si è visto che la navigazione nei browser ha problemi di isolamento: es. metti che apro una tab con il sito di homebanking e una con un link che mi è stato mandato per posta (\textit{LOL}). Che succede? Un bordello.\\
Allora si è pensato fosse meglio isolare ciò che succede in ogni tab, in modo che una pagina probabilmente compromessa non vada a disturbare le altre. Per fare ciò, si è pensato di applicare un processo distinto ad ogni tab del browser, in modo che ogni immagine a sé stante non possa andare a disturbare le altre.\\
Utile però sarebbe far comunicare in modo disciplinato fra un processo e l'altro. Dunque, più processi possono essere indipendenti o cooperare.\\
Un processo coopera con uno o più altri processi se il suo comportamento "influenza" o "è influenzato da" il comportamento di questi ultimi.\\
Possibili motivi per avere più processi cooperanti:
\begin{itemize}
    \item Condivisione informazioni
    \item Accelerazione computazioni
    \item Modularità ed isolamento (come in Chrome)
\end{itemize}
% \begin{wrapfigure}{r}{0.3\textwidth}
%     \begin{center}
%         \includegraphics[width=0.3\textwidth]{images/aa2324/SO_IPC1.jpg}
%     \end{center}
% \end{wrapfigure}
Per permettere ai processi di cooperare il sistema operativo deve mettere a disposizione delle altre API per la comunicazione interprocesso, noi vedremo alcune primitive di comunicazione interprocesso (IPC).\\
Tra cui queste due categorie:
\begin{description}
    \item[Memoria condivisa (a sinistra):] vuol dire che in qualche modo le due immagini dei processi condividono una certa regione di memoria.
    \item[Message passing (a destra):] vuol dire che in qualche modo all'interno della memoria del s.o. viene messa una qualche coda di messaggi e quindi un processo può inserire dei messaggi nella coda e l'altro processo può prelevare i messaggi dalla coda.
\end{description}
\begin{center}
    \includegraphics[width=0.45\textwidth]{images/aa2324/SO_IPC1.jpg}
\end{center}

\subsection{IPC tramite memoria condivisa}
Viene stabilita una zona di memoria condivisa tra i processi che intendono comunicare.\\
Vedremo come si può implementare quando parleremo di gestione della memoria.\\
\textit{La comunicazione è controllata dai \textbf{processi} che comunicano, \textbf{non} dal \textbf{s.o.}}.\\
Un problema importante è permettere ai processi che comunicano tramite memoria condivisa di sincronizzarsi (un processo non deve leggere la memoria condivisa mentre l'altro la sta scrivendo).\\
Allo scopo i sistemi operativi mettono a disposizione ulteriori primitive per la sincronizzazione.

\subsection{IPC tramite message passing}
Permettono ai processi \textit{sia} di comunicare \textit{che} di sincronizzarsi.\\
I processi comunicano tra di loro senza condividere memoria, attraverso la mediazione del sistema operativo.\\
Questo mette a disposizione:
\begin{itemize}
    \item Un'operazione \texttt{send(message)} con la quale un processo può inviare un messaggio ad un altro processo.
    \item Un'operazione \texttt{receive(message)} con la quale un processo può (mettersi in attesa fino a) ricevere un messaggio da un altro processo.
\end{itemize}
Per comunicare due processi devono:
\begin{itemize}
    \item Stabilire un \textbf{link di comunicazione} tra di loro.
    \item Scambiarsi messaggi usando \texttt{send} e \texttt{receive}.
\end{itemize}

\subsubsection{Pipe}
Canali di comunicazione tra i processi (una forma di message passing).\\
Varianti:
\begin{itemize}
    \item Unidirezionale o bidirezionale.
    \item (se bidirezionale) Half-duplex o full-duplex.
    \item Relazione tra i processi comunicanti (sono padre-figlio o no).
    \item Usabili o meno in rete.
\end{itemize}
Pipe convenzionali:
\begin{itemize}
    \item Unidirezionali.
    \item Non accessibili al di fuori del processo creatore\dots
    \item \dots quindi di solito condivise con un processo figlio attraverso una \texttt{fork()}.
    \item In Windows sono chiamate "\textit{pipe anonime}".
\end{itemize}
Pipe convenzionali:
\begin{itemize}
    \item Bidirezionali
    \item Esistono anche dopo la terminazione del processo che le ha create.
    \item Non richiedono una relazione padre-figlio tra i processi che le usano.
\end{itemize}
In Unix:
\begin{itemize}
    \item Half-duplex
    \item Solo sulla stessa macchina
    \item Solo dati byte-oriented
\end{itemize}
In Windows:
\begin{itemize}
    \item Full-duplex    
    \item Anche tra macchine diverse
    \item Anche dati message-oriented
\end{itemize}

\subsection{Notifiche con callback}
In alcuni sistemi operativi (es. API POSIX e Win32) un processo può notificare un altro processo in maniera da causare l'esecuzione di un blocco di codice («callback»), similmente ad un interrupt.\\
Nei sistemi Unix-like (POSIX, Linux) tale notifiche vengono dette segnali, ed interrompono in maniera asincrona la computazione del processo corrente causando un salto brusco alla callback di gestione, al termine della quale la computazione ritorna al punto di interruzione.\\
Nelle API Win32 esiste un meccanismo simile, detto Asynchronous Procedure Call (APC), che però richiede che il ricevente si metta esplicitamente in uno stato di attesa, e che esponga un servizio che il mittente possa invocare.

\section{Le API POSIX per la comunicazione interprocesso}
\subsection{Memoria condivisa in POSIX}
• Un processo crea un segmento di memoria condivisa con la funzione
shm_open:
int shm_fd = shm_open(name, O_CREAT | O_RDWR, 0666);
• Anche usato per aprire un segmento precedentemente creato
• Quindi imposta la dimensione del segmento con la funzione ftruncate:
ftruncate(shm_fd, 4096);
• Infine la funzione mmap mappa la memoria condivisa nello spazio di
memoria del processo:
void *shm_ptr = mmap(0, 4096, PROT_WRITE, MAP_SHARED, shm_fd, 0);
• Da questo momento si può usare il puntatore shm_ptr ritornato da mmap
per leggere/scrivere la memoria condivisa

\subsection{Pipe anonime in POSIX}
• Vengono create con la funzione pipe, che ritorna due descrittori, uno
per il punto di lettura e uno per il punto di scrittura:
int p_fd[2];
int res = pipe(p_fd);
• Le funzioni read e write permettono di leggere e scrivere:
ssize_t n_wr = write(p_fd[1], "Hello, World!", 14);
char buffer[256];
ssize_t n_rd = read(p_fd[0], buffer, sizeof(buffer) - 1);
P.S.: di solito si usa la pipe quindi la \texttt{fork()} per comunicare tra processi padre e figlio.
• È possibile utilizzare la funzione fdopen per fare il wrapping di un punto della pipe in un file, ed utilizzare le funzioni C stdio con esso

\subsection{Named pipes in POSIX}
• Le named pipes vengono anche chiamate FIFO nei sistemi POSIX
• Per creare una FIFO si utilizza l’API mkfifo:
int res = mkfifo("/home/pietro/myfifo", 0640);
• La FIFO si utilizza come un normale file:
int fd = open("/home/pietro/myfifo", O_RDONLY);
char buffer[256];
ssize_t n_rd = read(fd, buffer, sizeof(buffer) - 1);
• Al termine dell’utilizzo, ricordarsi di chiudere:
close(fd);
• Per eliminare la FIFO, usare l’API unlink:
unlink("/home/pietro/myfifo");

\subsection{Segnali POSIX}
Per inviare un segnale ad un processo utilizzare l’API kill:
int ok = kill(1000, SIGTERM); /* terminazione al processo 1000 */
Per registrare una callback per un determinato segnale utilizzare l’API
sigaction:
struct sigaction act;
sigemptyset(&act.sa_mask); /* non bloccare altri segnali */
act.sa_flags = SA_SIGINFO; /* callback in act.sa_sigaction */
act.sa_sigaction = sigterm_handler; /* la callback */
int ok = sigaction(SIGTERM, &act, NULL);

\section{Multithreading}
Fino ad ora abbiamo assunto che un processo abbia un singolo flusso di esecuzione sequenziale (ossia, un singolo processore virtuale).\\
Se supponiamo che un processo possa avere molti processori virtuali, più istruzioni possono eseguire concorrentemente, e quindi il processo può avere più percorsi (thread) di esecuzione concorrenti.

\subsection{Processi single e multithreaded}
\begin{wrapfigure}{l}{0.3\textwidth}
    \begin{center}
        \includegraphics[width=0.3\textwidth]{images/aa2324/SO_Multithreading1.jpg}
    \end{center}
\end{wrapfigure}
I thread di uno stesso processo condividono la memoria globale (data), la memoria contenente il codice (code) e le risorse ottenute dal sistema operativo (ad esempio i file aperti).\\Ogni thread di uno stesso processo però deve avere un proprio stack, altrimenti le chiamate a subroutine di un thread interferirebbero con quelle di un altro thread concorrente.\\
Qua non è messo ma anche lo heap è condiviso.\\
\textbf{Tipica domanda dell'esame: come funziona}.

\subsubsection{Librerie di thread}
I thread si sfruttano tramite delle \textit{librerie di thread}.\\
Sono le API fornite al programmatore per creare e gestire thread. Librerie più in uso:
\begin{itemize}
    \item POSIX pthreads
    \item Windows threads
\end{itemize}

\section{Le API POSIX per il multithreading}
POSIX pthreads
• Non sono un’implementazione, ma una specifica (POSIX standard IEEE
1003.1c)
• Comune nei sistemi Unix e Unix-like (BSD, Linux, macOS)

\subsection{Creare un nuovo thread}
• All’inizio un processo viene creato con un singolo thread
• Per creare un nuovo thread si utilizza l’API pthread_create, per attendere la
fine dell’esecuzione di un thread si utilizza l’API pthread_join:
void *thread_code(void *name) { … }
…
pthread_id tid1, tid2;
int ok1 = pthread_create(&tid1, NULL, thread_code, "thread 1");
int ok2 = pthread_create(&tid2, NULL, thread_code, "thread 2");
…
void *ret1, *ret2;
ok1 = pthread_join(tid1, &ret1);
ok2 = pthread_join(tid2, &ret2);
…

\subsection{Aspetti particolari nelle API per il multithreading}
• Chiamate di sistema fork() ed exec()
• Gestione dei segnali
• Cancellazione dei thread
• Dati locali dei thread

\subsection{Chiamate di sistema fork() ed exec()}
• Una fork() dovrebbe duplicare solo il thread chiamante o tutti i
thread? Alcuni sistemi operativi Unix-like hanno due diverse fork()
• exec() invocata da un thread che effetto ha sugli altri thread? Di
solito termina tutti i thread del processo precedentemente in
esecuzione

\subsection{Gestione dei segnali}
• Quando un processo è single-threaded, un segnale interrompe l’unico
thread del processo
• Quando vi sono più thread, quale thread riceve il segnale?
• Possibili soluzioni:
• Il thread a cui si applica il segnale (ad es. il segnale SIGSEGV viene inviato al
thread che ha generato il segmentation fault)
• Ogni thread del processo
• Alcuni thread del processo
• Un thread speciale del processo deputato esclusivamente alla ricezione dei
segnali

\subsection{Cancellazione dei thread}
• L’operazione di cancellazione di un thread determina la terminazione
prematura del thread
• Può essere invocata da un altro thread
• Due approcci (\textbf{tipicamente chiesta all'esame}):
• Cancellazione asincrona: il thread che riceve la cancellazione viene terminato
immediatamente
• Cancellazione differita: un thread che supporta la cancellazione differita deve controllare periodicamente se esiste una richiesta di cancellazione pendente, e in tal
caso terminare la propria esecuzione
• Vantaggi:
• Cancellazione differita: dal momento che un thread controlla il momento della
propria cancellazione, può effettuare una terminazione ordinata
• Cancellazione asincrona: nessuna necessità di controllare periodicamente se ci sono
richieste di cancellazione pendenti

\subsection{Cancellazione nei POSIX pthreads}
• Si può attivare/disattivare la cancellazione, ed avere sia cancellazione
differita (default) che asincrona
• Se la cancellazione è inattiva, le richieste di cancellazione rimangono
in attesa fino a quando (se) è attivata
• In caso di cancellazione differita, questa avviene solo quando
l’esecuzione del thread raggiunge un punto di cancellazione (di solito
una chiamata di sistema bloccante)
• Il thread può aggiungere un punto di cancellazione controllando
l’esistenza di richieste di cancellazione con la funzione
pthread_testcancel()

\subsubsection{Esempio}
void *thread_code(void *name) {
 int oldtype, oldstate;
 pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, &oldtype);
 pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, &oldstate);
 while (true) {
 pthread_testcancel();
 … /* fa qualcosa di non interrompibile ma di durata finita */
 }
}
…
pthread_id tid;
int ok = pthread_create(&tid, NULL, thread_code, "thread 1");
… /* dopo un po' */
ok = pthread_cancel(tid);
void *ret;
ok = pthread_join(tid, &ret);

\subsection{Dati locali dei thread}
• In alcuni casi è utile assegnare ad un thread dei dati locali (thread
local storage, TLS) non condivisi con gli altri thread dello stesso
processo
• La TLS è diversa dalle variabili locali (ad es. è visibile a tutte le
funzioni)
• Simile ai dati static del linguaggio C, ma unica per ciascun thread
• Utile quando il programma non ha un controllo diretto sul momento
di creazione dei thread (es. quando si usano i thread pools)

\subsubsection{Nei POSIX pthreads}
• In POSIX i dati locali dei thread si possono creare utilizzando le
funzioni pthread_key_create(),
pthread_getspecific() e pthread_setspecific()
• pthread_key_create() crea un oggetto opaco di tipo
pthread_key_t, che può essere usato da tutti i thread per
identificare un dato locale
• pthread_setspecific() permette di associare ad una
pthread_key_t un valore di tipo void*
,
pthread_getspecific() di richiamarlo data la chiave
• Ogni thread può associare ad una stessa chiave il proprio distinto
valore locale (e successivamente richiamarlo)
Di solito non chiesti all'esame.