\chapter{Gestione della memoria: la struttura}
Argomenti
\begin{itemize}
    \item Allocazione contigua e protezione con registro base e limite
    \item MMU con registro di rilocazione
    \item Svantaggi dell'allocazione contigua
    \item Paginazione
    \item Swapping
    \item Grado di multiprogrammazione e utilizzazione dei processori
    \item Memoria virtuale
    \item Allocazione e sostituzione pagine (NON L'HA FATTO)
    \item Thrashing (NON L'HA FATTO)
\end{itemize}

\section{Allocazione contigua e protezione con registro base e limite}
Ricapitoliamo un po' di background\dots
\begin{itemize}
    \item Le aree di memoria che i processori possono usare direttamente per l'esecuzione dei programmi sono solo la memoria centrale ed i registri.
    \item Pertanto un programma deve essere portato dal disco in memoria centrale perché possa essere eseguito, e il programma deve avere anche sufficiente memoria centrale per memorizzare i risultati della computazione.
    \item La memoria centrale "vede" solo un flusso di indirizzi (richieste di lettura o scrittura) proveniente dal bus di sistema, e non è consapevole di chi ha generato tale flusso.
    \item Le operazioni sui registri richiedono un ciclo di clock (o anche meno).
    \item Viceversa, le operazioni sulla memoria richiedono molti cicli di clock, anche diverse centinaia, causando uno stallo (stall) del processore, durante il quale un core multithread può eseguire un altro thread hardware.\\
    Quando la CPU deve aspettare che il dato venga trasferito dalla memoria, non può computare (= stallo appunto).\\
    Le CPU moderne tuttavia sono multithreaded, quindi possono eseguire un altro thread hardware \textbf{in concorrenza} mentre aspettano che il dato venga trasferito dalla memoria.
    \item Per aumentare l'efficienza degli accessi in memoria vengono utilizzati diversi livelli di memorie cache tra processore e memoria centrale. L'accesso alla memoria centrale quindi viene mediato, le memorie cache sono più veloci (pochissimi registri mooolto veloci) della memoria centrale, ma hanno una capacità minore, e contengono una copia dei dati in memoria.\\
    Bene se il dato sta nella cache di primo livello.\\
    Benino se il dato sta nella cache di secondo livello.\\
    Male se il dato sta nella cache di terzo livello.\\
    Malissimo se il dato sta nella memoria centrale.\\
\end{itemize}
Il problema dell'allocazione della memoria:
\begin{itemize}
    \item Perché un processo possa andare in esecuzione la sua immagine (codice + dati statici + stack + heap) deve essere presente in memoria centrale.
    \item In un sistema multiprogrammato, più immagini di più processi stanno contemporaneamente nella memoria centrale.
    \item Il sistema operativo deve, pertanto, allocare porzioni di memoria centrale ai diversi processi in funzione delle necessità di tali processi.
    \item Questo pone diversi problemi:
    \begin{enumerate}
        \item Che \textbf{strategie di allocazione} possiamo adottare?\\
        Come diamo ad ogni processo una sezione della memoria?
        \item Come \textbf{proteggiamo} la memoria del sistema operativo dai processi, e quella di ogni processo da ogni altro processo?\\
        In modo che non venga sovrascritta per sbaglio.
        \item Se un programma può essere caricato, in momenti diversi, in posizioni diverse della memoria, come possono le istruzioni del programma \textbf{referenziare} le diverse locazioni di memoria usate dal programma?\\
        Problema del binding.
    \end{enumerate}
\end{itemize}

\subsection{Strategie di allocazione: contigua}
\textbf{\underline{Primo problema dell'allocazione della memoria}}.
\begin{itemize}
    \item È la strategia più semplice di allocazione della memoria in un sistema multiprogrammato.
    \item La memoria centrale è partizionata in due zone, una per il \textit{s.o.} e una per i \textit{processi utente}.
    \item Ogni processo utente occupa un'area \underline{contigua} di memoria nella partizione dei processi utente, e in quell'area viene caricata la sua immagine.
\end{itemize}
\begin{center}
    \includegraphics[width=0.275\textwidth]{images/aa2324/SO_gestione_memoria_struttura1.jpg}
\end{center}

\subsection{Protezione con registro base e limite}
\textbf{\underline{Secondo problema dell'allocazione della memoria}}.
\begin{itemize}
    \item È il più semplice metodo di protezione utilizzabile con l'all. cont.
    \item Il processore possiede due registri, un registro base ed un registro limite.
    \item Il registro base contiene il più piccolo indirizzo della memoria fisica che il processo corrente ha il permesso di accedere.
    \item Il registro limite determina la dimensione dell'intervallo ammesso.
\end{itemize}
\begin{center}
    \includegraphics[width=0.375\textwidth]{images/aa2324/SO_gestione_memoria_struttura2.jpg}
\end{center}
\begin{itemize}
    \item I registri base e limite possono essere impostati solo in modalità di sistema.
    \item In modalità utente il processore proibisce tutte le operazioni di lettura/scrittura fuori dall'intervallo individuato dai registri base e limite.
    \item Nel caso in cui venga generato un indirizzo fuori dall'intervallo, l'indirizzo non viene messo sul bus e viene generata un'eccezione.
    \item In modalità di sistema il processore può accedere a tutta la memoria.
\end{itemize}
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/SO_gestione_memoria_struttura3.jpg}
\end{center}

\section{MMU con registro di rilocazione}
MMU = memory management unit.

\subsection{Svantaggi della soluzione con registro base e limite}
La soluzione con registro base e limite ha uno svantaggio: non fornisce uno spazio di indirizzamento virtuale ai processi.\\
L'unico modo per implementare uno spazio di indirizzamento virtuale con tale soluzione sarebbe il binding in fase di caricamento.\\
Ma questo è molto lento!\\
Pertanto si preferiscono soluzioni basate sul binding in fase di esecuzione.

\subsection{Indirizzi logici e fisici}
Gli indirizzi generati dalla CPU quando esegue un programma sono detti indirizzi logici.\\
Gli indirizzi che arrivano alla memoria centrale sono detti indirizzi fisici.\\
Il binding in fase di esecuzione è l'unico metodo nel quale indirizzi logici e fisici differiscono.\\
La memory management unit (MMU) è il dispositivo hardware che traduce indirizzi logici in indirizzi fisici.\\
La MMU interviene solo in modalità utente: In modalità kernel gli indirizzi generati dalla CPU sono direttamente indirizzi fisici.\\
(Quindi, se il sistema operativo deve accedere alla memoria di un processo, deve tradurre "manualmente" gli indirizzi logici del processo in fisici).
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/SO_gestione_memoria_struttura4.jpg}
\end{center}

\subsection{MMU con registro di rilocazione}
\textbf{\underline{Terzo problema dell'allocazione della memoria}}.\\
La MMU più semplice utilizzabile con lo schema di allocazione contigua è la MMU con registro di rilocazione.\\
È una variazione dello schema con registri base e limite, dove il registro base è ora chiamato registro di rilocazione.\\
L'indirizzo fisico è ottenuto sommando all'indirizzo logico il valore del registro di rilocazione.\\
In tal modo i programmi hanno l'illusione di avere uno spazio di indirizzamento virtuale che va dall'indirizzo 0 a un indirizzo massimo pari al valore contenuto nel registro limite.\\
Nel registro base viene caricato l'indirizzo più basso dell'area contigua di memoria assegnata al processo.\\
Nel registro limite viene caricata la dimensione di tale area di memoria.\\
Se l'indirizzo logico supera tale valore, viene generata un'interruzione (intercettata dal S.O., che di solito interrompe il processo).
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/SO_gestione_memoria_struttura5.jpg}
\end{center}

\section{Svantaggi dell'allocazione contigua}
\subsection{A.c. a partizioni variabili}
\begin{itemize}
    \item Ogni processo ottiene una partizione di memoria distinta
    \item Schema a partizioni variabili: partizione di dimensione pari alla memoria necessaria al processo.
    \item Un buco è una regione di memoria libera contigua, ed ogni processo riceve la sua partizione di memoria da un buco abbastanza grande da contenerla.
    \item Quando un processo termina libera la sua partizione creando un nuovo buco, e buchi adiacenti sono uniti. Abbiamo un problema di \textbf{frammentazione}.
\end{itemize}
\begin{center}
    \includegraphics[width=0.5\textwidth]{images/aa2324/SO_gestione_memoria_struttura6.jpg}
\end{center}
E che succede se quando ho solo processo 9 e processo 2, mi arrivasse un processo 10 con una memoria più grande di uno dei buchi lasciati dai processi terminati, ma più piccola della loro somma? Siamo in uno schema di partizioni contigue, non posso frammentarla: devo spostare un processo (tipo il 9).

% 13/12/2023
Un problema introdotto dall'allocazione contigua a partizioni variabili è quello della frammentazione della memoria in partizioni non contigue e non sufficientemente grandi per accogliere immagini di processi.\\
Ci sono diverse strategie di allocazione contigua a partizioni variabili.
\begin{itemize}
    \item Il sistema operativo mantiene una lista dei buchi disponibili sparsi nella memoria centrale.
    \item Alla creazione di un nuovo processo il sistema operativo sceglie un buco dal quale prendere la memoria necessaria ad esso secondo una strategia:
    \begin{description}
        \item[• \texttt{First-fit}:] scelgo il primo buco sufficientemente grande da contenere l'immagine del processo\\
        Non sempre è la scelta migliore.
        \item[• \texttt{Best-fit}:] scelgo il più piccolo buco che basta per il processo, in modo da ridurre lo spreco (se ne uso uno troppo grande magari avanza tanto spazio che potrebbe però non essere sufficiente a conservare altri processi e andrebbe quindi sprecato).
        \item[• \texttt{Worst-fit}:] scelgo il buco più grande possibile in modo che tutto lo spazio che avanzi sia sufficiente per altri processi.\\
        Ma questo non è detto che avvenga, quindi è l'approccio meno buono, tuttavia ancora usato da alcuni s.o.
    \end{description}
    \item \texttt{First-fit} e \texttt{best-fit} sono sperimentalmente migliori in quanto ad efficienza. Il più veloce è senza dubbio \texttt{best-fit}.
\end{itemize}

\subsection{Frammentazione}
Abbiamo due tipi di \textbf{frammentazione}:
\begin{description}
    \item[• Frammentazione esterna:] la memoria libera è sufficiente per la creazione di un nuovo processo, ma è sparsa tra buchi non contigui troppo piccoli.
    \item[• Frammentazione interna:] se la memoria allocata ad un processo è più grande della memoria necessaria, una partizione può contenere memoria inutilizzata.
\end{description}
Nell'allocazione contigua a partizioni variabili, non essendoci frammentazione interna, quando spazio si spreca per la frammentazione esterna? Statisticamente si è trovato che lo spazio utilizzato che lo spazio inutilizzabile tende ad essere circa il 50\% dello spazio utilizzato (parliamo della \textit{regola del 50\%}). Ecco perché nessuno tende più ad usare l'allocazione contigua a partizioni variabili.\\
Un possibile rimedio è la \textbf{compattazione} (o \textbf{deframmentazione}):
\begin{itemize}
    \item Spostare le partizioni in maniera da poter unire buchi separati
    \item Richiede binding in fase di esecuzione (rilocazione dinamica)
    \item È molto onerosa in termini computazionali
    \item Inoltre se il processo effettua I/O non può essere rilocato; alternativamente, l'I/O va fatto solo in buffer interni al sistema operativo.\\
    Ovvero, tutte le volte che un processo è in \texttt{wait()} (per l'I/O, ma in particolare per I) è molto difficile spostare la sua immagine nella sua destinazione perché poi il kernel non sa dove andare a scrivere e salvare i dati letti in input mentre veniva spostato.
\end{itemize}
La frammentazione è un problema generale che si verifica anche nelle memorie secondarie.

\section{Paginazione}
Nei sistemi più moderni si usa la \textbf{paginazione} per risolvere il problema della frammentazione esterna.

\subsection{Paginazione}
• Idea: permettere una allocazione di memoria ai processi \textit{non contigua}.
• Col supporto di hardware (serve una MMU più complessa) va a dividere la memoria centrale in \textbf{frames}, ossia blocchi di dimensione fissa (tra 512 bytes e 16 Mbytes).
• Similmente lo spazio di indirizzamento virtuale di ogni processo è diviso in pagine, ossia blocchi delle stesse dimensioni dei frames
• Una tabella delle pagine associa le pagine di un processo ai frames in memoria centrale, e permette alla MMU di tradurre gli indirizzi logici in
fisici
• Vantaggi:
• Non vi è più frammentazione esterna
• Vi è piena indipendenza tra indirizzi logici e indirizzi fisici (ad esempio, si possono avere indirizzi logici a 64 bit anche se la memoria fisica è più piccola)
• Svantaggi: frammentazione interna











