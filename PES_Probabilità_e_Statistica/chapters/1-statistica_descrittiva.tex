\chapter{Statistica Descrittiva}
Che cos'è la statistica? La statistica è l'arte di imparare dai dati.
La statistica si divide in tre rami: \textbf{Statistica Descrittiva}, Porbabilità e Statistica inferenziale.
La statistica descrittiva é il ramo della statistica che ci permette di \textbf{Descrivere i dati}.
\section{Descrivere i dati}
Se misuriamo una variabile in un campione otteniamo un insieme di dati:
$$x_1, x_2, ..., x_N \text{ con N Numero di dati}$$
Se questo insieme contiene un \emph{numero ridotto di valori distinti}, per descrivere questi dati
in maniera chiara e immediata è utile riassumerli in una \textbf{tabella delle frequenze}:
\begin{center}
    \begin{tabularx}{.95\textwidth}{ c|X|X }
        Valori & Frequenza Assoluta $F_i$ & Frequenza Relativa $P_i$ \\
        \hline
        &&
    \end{tabularx}
\end{center}
Notiamo che abbiamo due tipi di frequenza:
\begin{itemize}
    \item Frequenza Assoluta $F_i$: Numero di volte in cui compare $i$ nell'insieme di dati.
    \item Frequenza Relativa $P_i$ :Frazione di volte in cui compare $i$ nell'insieme di dati ($P_i = F_i / N$)
\end{itemize}
Il dato che compare con frequenza più alta è detto \textbf{Moda}.
\paragraph{Tipi di dati}I dati possono essere di due tipi:
\begin{itemize}
    \item Qualitativi, ovvero "categorie".
    \item Quantitativi, ovvero numerici.
\end{itemize}
In questo corso useremo i dati \textbf{quantitativi}.

\subsection*{Rappresentare i dati}
Per rappresentare i dati attraverso le frequenze risulta efficace e immediato l'utilizzo di un \textbf{istogramma},
ovvero un grafico a barre che rappresenta la tabella, da cui chiaramamente è possibile risalire alla tabella stessa.

\paragraph{Raggruppamento dei Dati}
Capita spesso di avere degli insiemi di dati che assumono un numero elevato di \textbf{valori distinti}, 
in questi casi puó essere conveniente suddividerli in classi e determinare la frequenza di ciascuna classe.

In questo modo c'è una perdita d'informazioni (sui valori specifici),ma spesso non è un problema e così facendo possiamo
calcolare le frequenze delle classi e avere un'idea migliore della distribuzione dei dati.

\subsection{Dati Bivariati}
Quando per ciascun individuo vengono misurate due variabili ci troviamo un insieme di N dati a coppie detti \textbf{dati bivariati}.
$$(x_1,y_1), (x_2,y_2), ..., (x_N, y_N)$$
Queste coppie di dati sono \emph{inseparabili}.\\
Anche in questo caso è possibile calcolare le frequenze, sia assolute che relative, dette \textbf{frequenze congiunte}.

\paragraph{Correlazione}
Se facciamo un \emph{Diagramma di dispersione} (o scatterplot), possiamo evidenziare se c'è una correlazione tra i dati osservandone la tendenza.
\osservazione{
    \begin{center}
        CORRELATION $\neq$ CAUSATION
    \end{center}
    \paragraph{Correlazione non significa causalità!} Non è detto che l'aumento di una variabile causi la diminuzione dell'altra o viceversa, potrebbe esserci una causa comune. 
}

\section{Riassumere i dati}
Dopo aver rappresentato i dati vogliamo ora riassumerli mediante quantità numeriche, dette \textbf{Statistiche Campionarie}, al fine di sintetizzare le proprietà
salienti dei dati.

\subsection{Media Campionaria}
La Media Campionaria $\overline{x}$ é una metrica utile per caratterizzare l'insieme di dati:
\definizione{
    La Media Campionaria dei dati $x_i$ contenuti in un insieme di $N$ valori è:
    $$ \overline{x} := \frac{\sum_{i=1}^{N} x_i}{N}$$
}

\paragraph{Media da una tabella}
Se ho una tabella delle frequenze è intuitivamente facile fare una media campionaria partendo da essa:
\begin{center}
    \begin{tabular}{ c|c }
        Valori & Freq\\
        \hline
        $z_1$& $f_1$ \\
        $z_2$& $f_2$ \\
        $\vdots$ & $\vdots$ \\
        $z_N$& $f_N$ 
    \end{tabular}
    $ \implies \overline{x} := \frac{\sum_{i=1}^{N} z_i \cdot f_i}{\sum_{i=1}^{N} f_i}$
\end{center}

\paragraph{Trasformazioni Lineari Affini dei dati}
Quando faccio una trasformazione lineare, per esempio nei cambi di unitá di misura, anche la media è lineare:
$$ (y_i := a x_i + b)_{i=1,...,N} \text{ con } a,b \in \R $$
$$ \overline{y} = a \overline{x} + b $$


\subsection{Mediana Campionaria}
La Mediana é il valore centrale dell'insieme ordinato.
\definizione{
    Dato un insieme \textbf{Ordinato} di $N$ dati, la Mediana $m$ é cosí definita:
    \begin{itemize}
        \item se $N$ dispari: $m := x_{(\frac{N+1}{2})}$
        \item se $N$ pari $m := \frac{x_{(\frac{N}{2})}+x_{(\frac{N}{2}+1)}}{2}$
    \end{itemize} 
}
Ovvero se abbiamo un numero dispari di elementi, la mediana é il valore $(\frac{N+1}{2})$ esimo della lista (ovvero il valore centrale), se invece abbiamo
un numero pari di elementi, la mediana è la media dei due valori centrali ($\frac{N}{2}$ e $\frac{N}{2}+1$).

\osservazione{
La mediana è insesibile alle code, se per esempio quindi aumento anche di molto il valore dell'ultima cifra lasciando invariate
le altre la mediana non cambierà (a differenza della media).
}

\paragraph{Indici di Centralitá} Media e Mediana rappresentano "Indici di Centralitá", ovvero descrivono il 'centro' dell'insieme di dati.

\subsection*{Moda} La moda é un indice meno importante per la rappresentazione di un insieme e indica il dato con la frequenza assoluta Maggiore.

\section{Percentili e quantili}
Per analizzare la distribuzione dei dati è utile usare una generalizzazione della mediana chiamato \textbf{Percentile Campionario}.
\definizione{
    Il K-Esimo Percentile Campionario di un insieme di dati é il valore $t$ per cui:
    \begin{itemize}
        \item almeno il $k\%$ dei dati è $ <= t$
        \item almeno il $(100 -k)\%$ dei dati è $>= t$
    \end{itemize}
}
In pratica, il $k$-esimo percentile indica che il $k\%$ dei dati sará a sinistra dell'indice, il restante a destra.

\subsection{Quantili}
Eistono dei casi importanti (in quanto piú utilizzati) di percentili detti \textbf{Quantili}, questi casi più importanti sono per $k = 25$, $50$ e $75$.

Definiamo $k = 100p$, quindi $p=\frac{k}{100} \in [0,1]$.
I tre Quantili importanti sono:
\begin{itemize} 
    \item Primo Quartile $p = \frac{1}{4}: k = 100p$ = 25-esimo percentile ($q_1$)
    \item Secondo Quartile $p = \frac{1}{2}: k = 100p$ = 50-esimo percentile ($q_2$) 
    \\ Equivalente alla  mediana $m$.
    \item Terzo Quartile $p = \frac{3}{4}: k = 100p$ = 75-esimo percentile ($q_3$)
\end{itemize}
Questi Quartili partizionano i dati in tre parti, dandomi una idea della distribuzione dei dati.
\paragraph{Il Boxplot}
Il boxplot,  o grafico 'scatola e baffi' é la rappresentazione grafica dei quantili.
In questo grafico é anche possibile eliminare gli estremi \emph{Outliers}.
\nb{Esistono diverse definizioni di quantile, R per esempio ne utilizza una diversa di default.}


\subsection{Calcolo del k-esimo percentile}
Avendo $N$ dati, per calcolare il $k$-esimo percentile $t$ con $p=\frac{k}{100}$:
\begin{enumerate}
    \item Ordino l'insieme di dati $x_1 <= x_2 <= \dots <= x_n$
    \item Calcolo $t$:
        \begin{itemize}
            \item Se $N \cdot p$ non è intero $\implies t=x_i$, con $i= \lceil N \cdot p \rceil $
             \\\small{(t è il dato la cui posizione i è l'intero successivo a $N \cdot p$)}
            \item Se $N \cdot p$ è intero $\implies t = \frac{x_{(N\cdot p)} x_{(N \cdot p+1)}}{2}$
            \\\small{(t è la media aritmetica fra il dato in posizione $N \cdot p$ e il successivo)}
        \end{itemize}
\end{enumerate}

\section{Indici di Dispersione}
Ora vogliamo descrivere la dispersione dei dati di un insieme (ovvero l'ampiezza dei dati).

Fissiamo un insieme di dati e la sua media $\overline{x}$.
Consideriamo gli "scarti" ($x_i-\overline{x}$) rispetto alla media. Se sommiamo tutti gli scarti otterremo 0, perché gli scarti positivi e negativi si compensano.
\\Quindi, se vogliamo considerare la dispersione non uso solo gli scarti ma il loro \textbf{Quadrato} $(x_i-\overline{x})^2$, ottenendo cosí solo valori positivi.
Se faccio una sorta di media di questi valori ottengo la \textbf{Varianza Campionaria}
\definizione{
    Si definisce \textbf{Varianza Campionaria} la 'media' del quadrato degli scarti rispetto alla media:
    \formula{Varianza Campionaria}{$S^2 = \frac{1}{N-1} \cdot \sum_{i=1}^{N} (x_i-\overline{x})^2$}
}
Come mai faccio la 'media' con $N-1$? lo scopriremo piú avanti.
\\Una \emph{Forma Alternativa} della varianza che é piú facile da calcolare é: 
\[
    S^2 = \frac{1}{N-1} \cdot ( \sum_{i=1}^{N} x_i^2- N \cdot \overline{x}^2)  
\]
\paragraph{Deviazione Standard} La varianza campionaria quindi mi rappresenta una media degli scarti elevati al quadrato, di conseguenza se i dati hanno una unitá di misura
la varianza $S^2$ avrá la stessa unitá ma al quadrato.

Per avere una statistica omogenea ai dati utilizzo la \textbf{Deviazione Standard}:
\definizione{
    Si definisce \textbf{Deviazione Standard} la radice quadrata della varianza campionaria:
    \formula{Deviazione Standard}{$S=\sqrt{S^2} = \sqrt{\frac{1}{N-1} \cdot \sum_{i=1}^{N} (x_i-\overline{x})^2}$}
}
Essa rappresenta la dispersione dei dati rispetto a $\overline{x}$, ovvero la 'larghezza' della distribuzione.

\osservazione{Sia La varianza che la deviazione standard sono sempre maggiori o uguali a zero $S^2 \geq 0, S\geq 0$.
Inoltre, $S^2 = S = 0$ sse tutti i dati sono \underline{uguali}, quindi ogni $x_i = \overline{x}$  
}

\paragraph{Utilitá} Esiste una disuguaglianza, detta di Chebyschev, da cui segue il Teorema:
\\ Dato un $c>0$, l'intervallo intorno ad $\overline{x}$ di ampiezza proporzionale ad $S$:
$$ (\overline{x} - c\cdot S, \overline{x} + c\cdot S)$$
Contiene una frazione $\alpha \geq 1 - \frac{1}{c^2}$ di dati.
\\esempio: Almeno il 75\% dei dati sono contenuti nell'intervallo $(\overline{x} - 2\cdot S, \overline{x} +2\cdot S)$ con $c=2$.

\paragraph{Trasformazioni lineri affini e Varianza/Deviazione}
Se abbiamo una trasformazione lineare affine $(y_i = a \cdot x_i + b)$ sappiamo che la Media é lineare, peró:
\begin{itemize}
    \item la Varianza NON é lineare : $S_y^2 = a^2 \cdot S_x^2$
    \item la Deviazione Standard NON é lineare : $S_y = |a|\cdot S_x$
\end{itemize}
Notiamo che $b$ non appare in varianza e deviazione perché "trasla" la dispersione ma non la modifica.

\subsection{Scarto Interquartile}
La deviazione standard va a misurare la dispersione dei dati in base alla \emph{media}, 
Definiamo quindi ora una dispersione per la \textbf{Mediana} come lo scarto Interquartile:
\formula{Scarto Interquartile}{$\Delta = q_3 - q_1$}
Notiamo che l'intervallo $[q_1,q_3]$ contiene almeno il 50\% dei dati.

\section{Coefficiente di correlazione lineare}
Se abbiamo dei dati bivariati possiamo, attraverso la deviazione standard, quantificarne la \textbf{Correlazione}.
Posso misurare il grado e la 'direzione' di correlazione di una coppia di dati attraverso il coefficiente di correlazione lineare. 

\formula{Coefficiente di Correlazione Lineare}{$ r = \frac{\sum_{k=1}^N (x_i - \overline{x})(y_i - \overline{y})}{(N -1)\cdot S_x \cdot S_y}$}
Si può mostrare che: $-1<=r<=1$
\\Dal coefficiente $r$ si possono ottenere il tipo di correlazione:
\begin{itemize}
    \item $r > 0$ indica una \textbf{Correlazione Positiva }
    \item $r < 0$ indica una \textbf{Correlazione Negativa }
\end{itemize}
E anche il grado di correlazione:
\begin{itemize}
    \item $|r| > 0.7$ indica una \textbf{Correlazione Significativa}
    \item $|r| < 0.3$ indica una \textbf{Correlazione Debole}
\end{itemize}
Si nota che questi valori sono arbitrari, vanno solo a indicare che piú $r$ si avvicina a $\pm 1$ e piú la correlazione é forte.