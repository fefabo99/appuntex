\chapter{Ottimizzazione Non Lineare Vincolata}
Consideriamo un generico problema di Ottimizzazione Non Lineare Vincolata:

\begin{center}
    opt $f(x)$
    \\s.a. $g_i(x) \{ =/\leq/\geq\} l$ con i= $1,...,m$
\end{center}
In questo caso \emph{Non esistono algoritmi di risoluzione}, ma ci sono diversi approcci per semplificare
e risolvere il problema.

\paragraph{Gli approcci} che affronteremo noi sono:
\begin{itemize}
    \item Dimensionality Reduction
    \item Moltiplicatori di Lagrange
    \item Condizioni di Karush-Kuhn-Tucker
\end{itemize}

\section{Dimensionality Reduction}
L'approccio del Dimensionality Reduction (o riduzione del numero delle variabili libere) consiste nell'utilizzare
i vincoli di uguaglianza del problema per ridurre il problema a un PNL Monovariato non vincolato.

\subsection{Facciamo un Esempio}
Dato il problema:
\begin{center}
    min $(x_1 - 2)^2 + 2(x_2-1)^2$
    \\s.a. $x_1+4x_2 =3$
\end{center}
Possiamo Esplicitare $x_1$ nel vincolo:
\[
    x_1+4x_2 =3 \to x_1 = 3 - 4x_2  
\]
Per poi sostituirlo nella funzione obiettivo:
\[
    \text{min }(x_1 - 2)^2 + 2(x_2-1)^2 \to  \text{min }(3 - 4x_2 - 2)^2 + 2(x_2-1)^2
\] 
In modo da ottenere un problema di ottimizzazione in una variabile, che possiamo risolvere analiticamente:
\[ \text{min }(3 - 4x_2 - 2)^2 + 2(x_2-1)^2 \implies x_2=\frac{1}{3}\]
Da cui, con la funzione obiettivo originale troviamo $x_1=\frac{5}{3}$.
In questo modo otteniamo la soluzione $(\frac{5}{3}, \frac{1}{3})$.

\subsection{É un metodo generalizzabile?}
Non sempre il metodo del Dimensionality Reduction é generalizzabile. Quando é possibile?
\\Supponiamo di avere un problema di $opt$ soggetto a $l$ vincoli di \emph{Uguaglianza}.
\textbf{SE} é possibile esplicitare $l$ variabili in funzione delle restanti $n-l$ variabili utilizzando i vincoli
di uguaglianza del problema, allora possiamo trasformare tale problema in un problema di $opt$ \emph{non vincolata} con $n-l$ variabili.

\begin{center}
    opt $f(x_1,...,x_n)$
    \\s.a. $g_j(x_1,...,x_n) =b_j$ con $j=1,...,l$
    \\$\Downarrow$
    \\opt $f(x_1,...,x_{n-l})$
    \\$x_{n-l+1} = g_1(x_1,...,x_{n-l})$
    \\ $\vdots$ 
    \\$x_{n} = g_l(x_1,...,x_{n-l})$
\end{center}
Questa condizione peró molto spesso NON é rispettata, quindi il Dimensionality Reduction non é sempre utilizzabile.

\section{Il metodo dei Moltiplicatori di Lagrange}
Il metodo dei Moltiplicatori di Lagrange é un metodo per trovare l'ottimo di problemi di PNL Vincolata.
Si basa sul concetto di Funzione Lagrangiana e sulle sue proprietá

\subsection{La Funzione Lagrangiana}
Per capire il metodo dei moltiplicatori di Lagrange, bisogna prima introdurre il concetto
di \emph{Funzione Lagrangiana}:
\definizione{
    Consideriamo un generico problema di PNL Vincolata con \emph{solo vincoli di uguaglianza}:
    \begin{center}
        opt $f(x_1,...,x_n)$
        \\s.a. $g_i(x_1,...,x_n) =0$ con $i=1,...,m$
    \end{center}
    La seguente funzione in $n+m$ variabili prende il nome di \textbf{Funzione Lagrangiana} del problema:
    \[
        L(x_1,...,x_n,\lambda_1,...,\lambda_m) = f(x_1,...,x_n) + \sum_{i=0}^{m} \lambda_i \cdot g_i(x_1,...,x_n)
    \]
    Le variabili $\lambda_j$, di cui ce ne sono tante quante i vincoli, prendono il nome di \textbf{Moltiplicatori di Lagrange}.
}

\paragraph{Come mai ci interessa la funzione Lagrangiana?}
I punti stazionari della funzione Lagrangiana (Ovvero i punti in cui il gradiente della lagrangiana si azzera)
sono \emph{Fortemente legati ai punti di massimo e minimo della funzione}.
\pagebreak
\subsection{Condizioni di Ottimalitá del Primo Ordine}
Consideriamo un generico problema di ottimizzazione non lineare del tipo:
\begin{center}
    opt $f(x_1,...,x_n)$
    \\s.a. $g_j(x_1,...,x_n) =0$ con $i=1,...,m$
\end{center}
E sia $x^* = (x^*_1,...,x^*_n)$ il punto stazionario di $f$. Allora:
\\ Esistono $m$ moltiplicatori di Lagrange $\lambda^* = (\lambda^*_1,...,\lambda^*_m)$ tali che
$(x^*,\lambda^*)$ è un punto stazionario della Lagrangiana Associata, ovvero
nel punto $(x^*,\lambda^*)$ \emph{Il gradiente della funzione Lagrangiana é nullo}.
Quindi il valore della Lagrangiana sará:
\[
        L(x^*,\lambda^*) = f(x^*) + \sum_{i=1}^{m} \lambda_i^* \cdot g_i(x^*)
\]
E avremo che:
\[
    \frac{\delta L(x^*,\lambda^*)}{\delta x_j} = 0 \text{ con } j=1,...,n
\]
\[
    \frac{\delta L(x^*,\lambda^*)}{\delta \lambda_i} = 0 \text{ con } i=1,...,m
\]
\paragraph{Osservazioni}
\begin{itemize}
    \item I punti $x^*$ e $(x^*,\lambda^*)$ possono essere punti stazionari \emph{di tipo diverso}.
    \item Tale condizione fornisce una \textbf{Condizione Necessaria ma Non Sufficiente} per l'ottimizzazione del problema vincolato.
    \item Come nel caso dell'ottimizzazione non vincolata, i punti che annullano il gradiente rappresentano i
        punti candidati ad essere punto di massimo/minimo della funzione. 
        Se $f$ é convessa, allora i punti stazionari sono punti di Minimo, se invece é concava i punti stazionari sono di Massimo.
\end{itemize}

\paragraph{Considerazioni}
Se prendiamo le due condizioni presentate notiamo che:
\begin{itemize}
    \item $\frac{\delta L(x^*,\lambda^*)}{\delta \lambda_i} = 0 \text{ con } i=1,...,m$
    é di fatto un modo "elegante" di riscrivere i vincoli $g_i(x_1,...,x_n)$.
    \item $\frac{\delta L(x^*,\lambda^*)}{\delta x_j} = 0 \text{ con } j=1,...,n$ puó essere riscritto come 
    \[
    \frac{\delta L(x^*,\lambda^*)}{\delta x_j} = 
    \frac{\delta f(x^*)}{\delta x_j} + \sum_{j=0}^{m} \lambda^*_i \cdot \frac{\delta g_i(x^*)}{\delta x_i} = 0
    \]
\end{itemize}
Inoltre, di fatto vogliamo trovare il \emph{Punto $(x^*,\lambda^*)$ in cui il gradiente di $L$ si azzera}:
\[
  \nabla L(x^*,\lambda^*) = \nabla f(x^*) + \sum_{i=1}^{m} \lambda_i^* \cdot \nabla g_i(x^*) = 0
  % \implies  \nabla f(x^*) =  - \sum_{i=1}^{m} \lambda_i^* \cdot \nabla g_i(x^*) 
\]
L'insieme dei vincoli di fatto restringe lo spazio delle soluzioni ammissibili del problema al sottospazio dato dall'intersezione dei vari vincoli.
Il gradiente della funzione nel punto di ottimo $x^*$ ($\nabla f(x^*)$) deve risultare ortogonale\footnote{In geometria elementare, di due enti che formano un angolo retto}
a tale sottospazio.
\\Siccome il vettore ortogonale a tale sottospazio é dato da $\sum_{i=1}^{m} \lambda_i^* \cdot \nabla g_i(x^*)$, dobbiamo quindi avere che
\[\nabla f(x^*) =  - \sum_{i=1}^{m} \lambda_i^* \cdot \nabla g_i(x^*) \]
Quest'ultima condizione significa che nel punto di ottimo il gradiente della funzione $f$ puó essere riscritto come combinazione lineare dei gradienti dei vincoli.

\subsection{Condizioni di Ottimalitá del Secondo Ordine}
Come nel caso dell'ottimizzazione non vincolata, abbiamo anche in questo caso delle condizioni sufficienti per garantire che i punti stazionari della Lagrangiana siano
punti di massimo/minimo della funzione f.

Sia $J$ la matrice dei gradienti nei vincoli (Matrice Jacobiana).
Consideriamo l'insieme dei vettori $y \in \R^n$ tali che:
\[
  J(x^*) \cdot y = 0
\]
Dove $J$ é una matrice $m$x$n$:
\[
    J(x^*) = \begin{bmatrix}
        \frac{\delta g_1}{\delta x_1} & \cdots & \frac{\delta g_1}{\delta x_n} \\
        \vdots & \ddots & \vdots \\
        \frac{\delta g_m}{\delta x_1} & \cdots & \frac{\delta g_m}{\delta x_n}
    \end{bmatrix} \to
    \begin{cases}
        \nabla g_1(x^*) \cdot y_1 = 0 & \\
        \cdots & \\
        \nabla g_m(x^*) \cdot y_m= 0 &
    \end{cases}
\]
Tale sottospazio rappresenta l'insieme dei vettori perpendicolari ai gradienti dei vari vincoli.

\paragraph{Minimo/Massimo}
Consideriamo la matrice Hessiana della funzione Lagrangiana ristretta alle variabili iniziali $x_1,...,x_n$:
\[
    H_L(x^*,\lambda^*) = \begin{bmatrix}
        \frac{\delta^2L}{\delta x_1^2} & \cdots & \frac{\delta^2L}{\delta x_1x_n} \\
        \vdots & \ddots & \vdots \\
        \frac{\delta^2L}{\delta x_1x_n} & \cdots & \frac{\delta^2L}{\delta x^2_n}
    \end{bmatrix}
\]
\begin{itemize}
    \item Condizione sufficiente affinché $x^*$ sia un punto di:
    \begin{itemize}
        \item Minimo: $y^T \cdot H_L(x^*,\lambda^*) \cdot y > 0$.
        \item Massimo: $y^T \cdot H_L(x^*,\lambda^*) \cdot y < 0$.
    \end{itemize}
    \item Condizione Necessaria affinché $x^*$ sia un punto di:
    \begin{itemize}
        \item Minimo: $y^T \cdot H_L(x^*,\lambda^*) \cdot y \geq 0$.
        \item Massimo: $y^T \cdot H_L(x^*,\lambda^*) \cdot y \leq 0$.
    \end{itemize}
\end{itemize}

\subsection{Procedura generale}
\begin{itemize}
    \item Si cercano i punti stazionari della Lagrangiana per ottenere i punti candidati ad essere punti di massimo/minimo:
        \[
            \frac{\delta L(x^*,\lambda^*)}{\delta x_j} = 0 \text{ con } j=1,...,n
        \]
        \[
            \frac{\delta L(x^*,\lambda^*)}{\delta \lambda_i} = 0 \text{ con } i=1,...,m
        \]
    \item Utilizzo le condizioni del secondo ordine per eliminare i punti stazionari che di sicuro non sono ne di minimo ne massimo, ovvero i punti di sella:
    \begin{itemize}
        \item Cerco $y$ t.c. $ J(x^*) \cdot y = 0$
        \item Se sistono $y_1$ e $y_2$ t.c. $y_1^T \cdot H_L(x^*,\lambda^*) \cdot y_1 > 0$ o $y_2^T \cdot H_L(x^*,\lambda^*) \cdot y_2 < 0$
        allora possiamo classificarlo come punto di sella.
    \end{itemize}
    \item Per i rimanenti punti:
    \begin{itemize}
        \item Se $y^T \cdot H_L(x^*,\lambda^*) \cdot y > 0$ o $y^T \cdot H_L(x^*,\lambda^*) \cdot y < 0$ allora possiamo classificarlo come punto di minimo o massimo.
        \item se $y^T \cdot H_L(x^*,\lambda^*) \cdot y \geq 0$ o $y^T \cdot H_L(x^*,\lambda^*) \cdot y \leq 0$ allora non possiamo essere certi che tale punto sia di Minimo o Massimo.
    \end{itemize}
\end{itemize}

\subsection{I vincoli di Disuguaglianza}
Cosa succede con il metodo dei Moltiplicatori di Lagrange se abbiamo anche dei vincoli di Disuguaglianza nel problema?

Se al generico problema di Programmazione non lineare vincolata \emph{aggiungiamo} dei vincoli di disuguaglianza:
\[
    h_j(x_1,...,x_n) \leq 0 \text{ con } j=1,...,p  
\]
E consideriamo un punto di ottimo $x^*$ avremo che:
\begin{itemize}
    \item Se $h_j(x^*)=0$ allora si dice che il vincolo é attivo
    \item Se $h_j(x^*)<0$ allora si dice che il vincolo non é attivo, e quindi un piccolo cambiamento non violerá il vincolo.
\end{itemize}
Qunidi in questo caso la \textbf{Lagrangiana Generalizzata} sará definita come una funzione in $n+m+p$ variabili:
\[
    L(x_1,..,x_n,\lambda_1,...,\lambda_m,\mu_1,...,\mu_n) = f(x_1,..,x_n) +  \sum_{i=1}^{m} \lambda_i \cdot g_i(x_1,..,x_n)  +  \sum_{j=1}^{p} \mu_j \cdot h_j(x_1,..,x_n) 
\]

\section{Condizioni di Karush-Kuhn-Tucker}
Le condizioni di Karush-Kuhn-Tucker rappresentano una generalizzazione del metodo dei moltiplicatori di lagrange,
appliccato ai problemi in cui siano presenti anche dei vincoli di disuguaglianza.

Consideriamo un generico problema di PNL Vincolata:
\begin{center}
    opt $f(x_1,...,x_n)$
    \\s.a. 
    \\$g_i(x_1,...,x_n) =0$ con $i=1,...,m$ Vincoli di Uguaglianza.
    \\$h_j(x_1,...,x_n) \leq 0$ con $j=1,...,m$ Vincoli di Disuguaglianza.
\end{center}
Sia $x^*(x_1,...,x_n)$ punto di ottimo di $f$, allora avremo che
$h_j(x^*)$ puó essere attivo ($h_j(x^*)=0$) o inattivo ( $h_j(x^*)<0$), e indichiamo con $I(x^*)$ l'insieme dei vincoli attivi.
Inoltre  esistono $m$ moltiplicatori $\lambda^* = (\lambda_1^*,...,\lambda_m^*)$ e $p$ moltiplicatori $\mu^* = (\mu_1^*,...,\mu_p^*)$
Tali che valgono le seguenti condizioni:
\begin{itemize}
    \item \textbf{Condizione di Stazionarietá}, Ovvero il gradiente della Lagrangiana deve essere $=0$
        \[\nabla f(x^*) + \sum_{i=1}^{m} \lambda_i^* \cdot \nabla g_i(x^*) + \sum_{j=1}^{p} \mu_j^* \cdot \nabla h_j(x^*) = 0 \text{\small{ Problemi di MIN}}\]
        \[\nabla f(x^*) - \sum_{i=1}^{m} \lambda_i^* \cdot \nabla g_i(x^*) - \sum_{j=1}^{p} \mu_j^* \cdot \nabla h_j(x^*) = 0 \text{\small{ Problemi di MAX}}\]
    \item \textbf{Ammissibilitá Primale}, per cui abbiamo che:
    \[g_i(x^*) = 0 \forall i = 1,...,m\]
    \[h_j(x^*) \leq 0 \forall j = 1,...,p\]
    \item \textbf{Annussibilitá Duale}
    \[\mu^*_j \geq 0 \forall j = 1,...,p\]
    \item \textbf{Condizioni di Complementarietá}
    \[\mu^*_j \cdot h_j(x^*) = 0 \forall j = 1,...,p\]
\end{itemize}
Osserviamo che le condizioni di Ammissibilitá Duale e di Complementarietá implicano che
nel caso di vincoli di disuguaglianza abbiamo che:
\begin{itemize}
    \item se $h_j(x^*) < 0$ (vincolo non attivo) allora $\mu^*_j = 0$
    \item se $h_j(x^*) = 0$ (vincolo attivo) allora $\mu^*_j \geq 0$
\end{itemize}
\paragraph{Considerazioni Importanti}
\begin{itemize}
    \item Le condizioni KKT rappresentano le condizioni necessarie ma non sufficienti che caratterizzano i punti di ottimo (condizioni di ottimalitá)
    \item I punti di ottimo devono soddisfare le condizioni di KKT
    \item Le condizioni KKT mi consentono di "limitare" la ricerca del/dei punto/i di ottimo tra i punti che soddisfano le condizioni.
    \item Le condizioni KKT non sono un algoritmo.
\end{itemize}

