\chapter{Branch and Bound}
Il Branch and Bound è una tecnica per la risoluzione di problemi di ottimizzazione intera.\\
Questa è una tecnica di \emph{enumerazione implicita}, ovvero:
\begin{itemize}
    \item "Valuta" le soluzioni possibili fino a trovare quella ottima.
    \item Scarta alcune di queste soluzioni a priori dimostrando la loro non ottimalità.
    \item Si basa sul concetto di Dividi et Impera.
\end{itemize}  
\section{Come funziona}
Supponiamo di avere un problema di PLI che chiamiamo \emph{problema completo}.
\\Un problema di PLI rappresenta un \textbf{sotto-problema} del problema completo se presenta la medesima funzione obiettivo, ma ha un sottoinsieme proprio di $X$ come regione ammissibile.
\definizione{Sia $z* = f(x*)$ la soluzione del problema completo e $\tilde{z} = f(\tilde{x}°)$ la soluzione ottima di un sotto-problema. Allora si ha che $f(\tilde{x}) \leq f(x*)$.}

Basta solo notare che tra le soluzioni ammissibili del problema completo vi è anche $\tilde{x}$ e che per definizione di ottimo $f(\tilde{x}) \leq f(x*)$.
\section{Le tecniche di risoluzione}
Il Branch and Bound fa uso delle tre seguenti tecniche per risolvere un generico problema di PLI:
\begin{itemize}
    \item \textbf{Branching}: La partizione rispetto al valore delle variabili.
    \item \textbf{Bounding}: La determinazione di un limite superiore.
    \item \textbf{Fathoming}:L'eliminazione di sottoproblemi.
\end{itemize}
La procedura del B\&B per i problemi di PB e quelli di PI è molto simile,
la differenza principale sta nella fase di Branching.

\subsection{Branching}
Il Branching è la fase di selezione del sotto-problema da analizzaree e la divisione di questo in sotto-problemi più piccoli.

Abbiamo due regole principali di selezione e divisione:
\begin{itemize}
    \item \textbf{Depth First}:Si sceglie il sotto-problema creato più di recente, ovvero il nodo di
    livello maggiore (più profondo).
    \begin{itemize}
        \item \textbf{Pros}: è semplice da implementare, permette di ottenere presto delle soluzioni ammissibili (ci si avvicina più rapidamente alle foglie) e limita la memoria necessaria per memorizzare l'albero delle soluzioni, visto che si tendono a chiudere molti nodi per inammissibilità e rimangono pochi nodi contemporaneamente aperti.
        \item \textbf{Cons}: presenta il rischio di esplorare completamente sotto-alberi con soluzioni scadenti.
    \end{itemize}
    \item \textbf{Best Bound}: Si sceglie il sotto-problema con il miglior bound, ovvero il "più promettente".
    (\textbf{lower bound} più \textbf{basso}, per problemi di \textit{minimo}, o \textbf{upper bound} più \textbf{alto}, per problemi di \textit{massimo}).
    in genere conduce a soluzioni incombenti più velocemente e quindi permette di effettuare un \textit{fathoming} più efficiente.
    \begin{itemize}
        \item \textbf{Pros}: permette di limitare il numero di nodi visitati esplicitamente e tende pertanto a essere più efficiente.
        \item \textbf{Cons}: l'esplorazione tende a rimanere a livelli poco profondi, dove i problemi sono meno vincolati e i bound sono più promettenti ma difficilmente si ottengono presto soluzioni ammissibili che migliorino la soluzione incombente corrente. Questo impedisce di applicare efficacemente le regole di \textit{fathoming}, pertanto è maggiore la richiesta di memoria per i nodi aperti contemporaneamente.
    \end{itemize}

    \item Si può anche usare una combinazione delle due regole: i nodi vengono scelti cioè alternando i diversi criteri, per evitare gli svantaggi di uno o dell'altro.
\end{itemize}

\subsubsection{Branching per problemi di PB (variabili binarie)}
Nel caso di problemi a variabili binarie (PB), il modo più semplice per dividere l'insieme delle soluzioni ammissibili in sotto-insiemi è fissare il valore di una delle variabili, per esempio $x_1 = 0$, per un sottoinsieme e a $x_1 = 1$ per l'altro sottoinsieme.\\
\begin{center}
    \includegraphics[width=0.5\textwidth]{img/B&B_PB1.jpg}
\end{center}
La variabile utilizzata ad ogni iterazione per eseguire questa suddivisione è chiamata \textbf{variabile di branching}. Nel diagramma qua sopra, al primo livello la variabile di branching sarà $x_1$, a quello successivo $x_2$ etc... Questo perché per selezionare ad ogni iterazione la variabile di branching si può utilizzare l'ordinamento naturale delle variabili ($x_1$, $x_2$, ...).
\\N.B.: nel caso binario, ad ogni branching generiamo due nuovi sotto-problemi, creando un albero binario.

\subsubsection{Branching per problemi di PI }
Differisce dal Branching per problemi di PB per poche cose. 
\paragraph{La variabile di Branching}
La prima differenza riguarda la scelta della variabile di \textit{Branching}:
Nel B\&B Binario si sceglievano le variabili in base all'indice, qui invece si sceglie una variabile che nella soluzione attuale è Non intera.
\paragraph{I valori delle variabili di Branching}
La seconda differenza riguarda i valori assegnati alla variabile per generare i sotto-problemi:
Se nel caso PB alla variabile di branching veniva assegnato il valore 0 e 1 rispettivamente per generare i due nuovi sotto-problemi, nella PLI non è possibile.
Nel caso generale vengono quindi generati due sotto-problemi specificando per la variabile due insiemi di valori:
$$x_j\, \le\, \lfloor x_j^* \rfloor\quad e\quad x_j\, \ge\, \lfloor x_j^* \rfloor\, +\, 1$$
 dove $\lfloor x_j^* \rfloor$ è il massimo intero per cui $\lfloor x_j^* \rfloor\, \le\, x_j^*$.

N.B.: può verificarsi che una stessa variabile venga selezionata più volte durante la procedura.

\subsection{Bounding}

Per ognuno dei sotto-problemi dobbiamo ricavare un limite, superiore per problemi di massimo e inferiore per problemi di minimo.
Per ottenere questo limite devo risolvere il problema rilassato, ovvero il problema senza considerare i vincoli di interezza ma limitando le variabili tra 0 e 1.
\\Quindi risolvo i miei sotto-problemi sostituendo l'ultima riga con i vincoli $x_j \ge 0 \wedge x_j \le 1$ (ovvero $0 \le x_j \le 1$).

Come prima cosa risolvo il rilassamento lineare (problema rilassato) del problema e ottengo un valore per la funzione Obiettivo. 
Essendo un problema binario o intero, se i coefficienti della funzione obiettivo sono tutti interi allora sicuramente il valore di $Z$ per il problema completo sarà intero.
Quindi posso arrontondare (per difetto per i problemi di max, per eccesso per i problemi di min) il valore di $Z$ del problema rilassato e rendere quel valore il mio Upper/Lower Bound.


\subsection{Fathoming}

Un sotto-problema può essere "eliminato" dalla lista dei problemi da considerare per tre possibili ragioni: 
\begin{enumerate}
    \item La soluzione ottenuta soddisfa i vincoli di interezza.
        La soluzione incombente cambierà ogni volta che un sotto-problema otterrà una soluzione intera migliore della soluzione incombente corrente.
    \item Se il bound di un sotto-problema è peggiore della soluzione incombente allora non vale la pena continuare a considerare il sotto-problema che quindi può essere chiuso.
    \item Il sotto-problema non ammette soluzioni ammissibili.
\end{enumerate}

Quindi verranno ulteriormente risolti ed analizzati solo quei problemi che non hanno una soluzione intera ma il loro bound è migliore della soluzione incombente.

% \section{Il rilassamento Lagrangiano}
% L'intero insieme di vincoli funzionali $\mathbf{Ax\, \le\, b}$ viene \textit{cancellato} (o \textit{quasi interamente cancellato}) e la funzione obiettivo $$Max\ Z\, =\, \mathbf{cx}$$ viene sostituita da $$Max\ Z\, =\, \mathbf{cx\, -\, \lambda(Ax - b)}$$
% Il problema $$Max\ Z\, =\, \mathbf{cx\, -\, \lambda(Ax - b)}$$ $$\,\quad s.t.\ \ge\: 0$$ è detto \textbf{\textit{problema Lagrangiano}} e ha la proprietà secondo la quale $\forall\, \lambda\, \ge\, 0$ fissato la sua soluzione ottima costituisce un \textbf{upper bound} sull'ottimo del problema originario di \textit{Max} (\textbf{lower bound} se il problema è di \textit{Min}).
% \\Il bound ottenibile con il \textit{rilassamento Lagrangiano} è quindi almeno tanto buono quanto quello ottenibile con il \textit{rilassamento lineare}.
% \subsubsection{Pro}
% L'efficacia pratica del rilassamento Lagrangiano è legata all'\underline{efficienza} con cui si riesce a \underline{risolvere il problema duale} del problema Lagrangiano.
% \subsubsection{Cons}
% Non è però efficiente come il rilassamento LP nel calcolare il \textit{primo} e il \textit{terzo} dei test di \textit{fathoming}.
% \subsubsection{I criteri di Fanthoming}
% Ricordando che i criteri di \textit{fathoming} derivanti dall'\underline{analisi di un problema rilassato}:
% \begin{itemize}
%     \item \textit{Criterio 1}: \`E stata trovata una soluzione ottima intera del sotto-problema.
%     \item \textit{Criterio 2}: La soluzione ottima $Z$ del sotto-problema deve essere peggiore della soluzione incombente $Z^*$ ($Z\, \le\, Z^*$ per un problema di \textit{Max} e \textit{viceversa} per un problema di \textit{Min}).
%     \item \textit{Criterio 3}: Il sotto-problema non presenta soluzioni ammissibili.
% \end{itemize}

% \section{Problemi con soluzioni ottime alternative}
% Potrebbe essere importante poter ottenere una lista delle soluzioni ottime, in modo che la scelta della soluzione migliore possa essere poi effettuata sulla base di considerazioni che potrebbero non essere state incluse nel modello matematico.
% \\Per trovarle basta fare alcune piccole modifiche:
% \begin{itemize}
%     \item Il test del Criterio 2 deve essere fatto sulla base della disugualianza stretta ($Z\, <\, Z^*$ per un problema di \textit{Max} e \textit{viceversa} per un problema di \textit{Min}).
%     \\In questo modo il \textit{Fanthoming} non avverrà se $Z\, =\, Z^*$.
%     \item Se la soluzione di un sotto-problema soddisfa il criterio 1 con $Z\, =\, Z^*$ allora anche questa soluzione deve essere memorizzata come incombente, e occorre controllare se il sotto-problema ammette soluzioni multiple. Nel qual caso occorre calcolare e memorizzare anche le soluzioni alternative come incombenti.
% \end{itemize}
% Alla fine della procedura tutte le soluzioni correnti incombenti (tutte \textit{equivalenti}) saranno considerate \textbf{ottime}.

% \section{Soluzioni "quasi-ottime"}
% Il Branch and Bound può essere utilizzato anche per trovare soluzioni "buone" (quasi-ottime) anche se non necessariamente ottime, che in genere richiedono uno sforzo computazionale molto minore.
% \\Una soluzione è considerata quasi-ottima quando la sua soluzione $Z$ è "abbastanza" vicina al valore di una soluzione ottima $Z^{**}$, ovvero $$Z^{**} -\, K \le Z$$ o equivalentemente $$(1\, -\, \alpha)Z^{**} \le\, Z$$ dove $K$ e $\alpha$ sono costanti date.
% \\N.B.: $\alpha$ mi rappresenta l'approssimazione (percentuale) della soluzione quasi-ottima trovata.
% \\Quindi se una soluzione incombente $Z^*$ soddisfa $$Z^{**} -\, K \le Z^*$$ oppure $$(1\, -\, \alpha)Z^{**} \le\, Z^*$$ 
% \\La procedura può terminare fornendo una soluzione $Z^*$ quasi-ottima.
% \\
% \\Ma come si può identificare quel valore $Z^{**}$?
% \\Se esistesse una soluzione ammissibile con valore $Z^{**}$ allora si avrebbe $Z^{**} \le\, Bound$ dove $Bound$ è la soluzione migliore tra quelle dei problemi rilassati ancora aperti.
% \\Quindi possiamo sostituire $Bound$ a $Z^{**}$ nelle formule precedenti ottenendo: $$Bound\, -\, K \le Z^*$$ oppure $$(1\, -\, \alpha)Bound\, \le\, Z^*$$
% \\Anche se la soluzione corrispondente a $Bound$ non è ammissibile (intera) costituisce comunque un limite superiore valido.
% \\Per problemi di grosse dimensioni considerare le soluzioni quasi-ottime può evitare tempi computazionali proibitivi.

\section{Criteri d'arresto}
Il metodo del Branch-and-Bound si arresta quando tutti i nodi sono dichiarati \textit{fathomed}. In questo caso, la soluzione ammissibile corrente corrisponde ad una soluzione ottima.
\\Si possono anche usare soluzioni quasi-ottime e fermarci non appena troviamo una soluzione quasi ottima. 
\\Oppure ancora possono anche essere adottati criteri relativi a limiti computazionali, come ad esempio raggiunti limiti di tempo di calcolo o di memoria, ma non è garantito che l'eventuale soluzione ammissibile corrente sia ottima (posso comunque calcolare quanto distante è dal $Bound$).

\section{Considerazioni finali sul B\&B}
\subsubsection{Valutazione di soluzioni ammissibili}
Per applicare efficacemente le regole di \textit{Fathoming}, è necessario disporre di soluzioni ammissibili di buona qualità. Bisogna quindi stabilire come e quando calcolare soluzioni ammissibili.
\\Abbiamo varie possibilità:
\begin{itemize}
    \item Aspettare che l'enumerazione generi un nodo foglia ammissibile;
    \item Implementare un algoritmo che valuti una buona soluzione prima dell'esplorazione;
    \item Sfruttare, con frequenza da valutare, l'informazione raccolta durante l'esplorazione dell'albero per costruire soluzioni ammissibili sempre migliori;
    \item In ogni caso, bisogna \textbf{sempre} valutare il compromesso tra la qualità della soluzione ammissibile corrente e lo sforzo computazionale per ottenerla.
\end{itemize}