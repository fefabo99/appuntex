\documentclass[12pt, a4paper, openany]{book}
\usepackage[inline]{enumitem}
\usepackage{../generalStyle}
\usepackage{amsmath}

\graphicspath{ {./img/} }

\begin{document}

\title{Esami di Ricerca Operativa e Pianificazione delle Risorse}
\author{
	Fabio Ferrario\\
	\small{\href{https://t.me/fefabo}{@fefabo}}
}

\date{2023}
\maketitle


\tableofcontents

\chapter{Domande di Teoria dal Mega}
Si faccia riferimento a un problema di Massimizzazione ed, ove richiesto, ad un problema artificiale per la fase 1 del metodo del simplesso.

\domandaaperta{1?}{Se B é la matrice di base associata ad una base ottima, il valore della funzione obiettivo associato alla corrispondende SBA  non negativo}

\domandaaperta{2}{Il valore Nullo di una variabile indica che essa sia fuori base}
\rispostaaperta{Falso, una variabile puó valere 0 anche nel caso sia in base (soluzione degenere)}

\chapter{Domande di Teoria - Bibbia}

\subsection{Programmazione Lineare e Metodo del Simplesso}

\affermazionetrue
{Un vertice ammissibile é una soluzione ammissibile che non giace lungo un segmento che connette altre due soluzioni ammissibili.}
{Dalla definizione}

\affermazionetrue
{Dato un vertice (soluzione) ammissibile, se non esiste uno spigolo, incidente in esso, cui compete un tasso positivo di miglioramento, allora la soluzione corrente é ottimale.}
{Il TEST DI OTTIMALITÀ consiste nel verificare se
esiste uno spigolo con tasso positivo di
miglioramento. Se tale condizione non è
soddisfatta allora la soluzione corrente è
ottimale.}

\affermazionefalse
{In ogni problema di PL con $n$ variabili di decisione e $m$ vincoli, ogni vertice ammissibile giace all'intersezione di n+m frontiere di altrettanti vincoli.}
{In ogni problema di programmazione lineare con $n$
variabili di decisione, ogni vertice ammissibile giace
all'intersezione di $n$ frontiere di altrettanti vincoli, }

\affermazionetrue
{Una soluzione che giace lungo un segmento che collega due altre soluzioni ammissibili non é un vertice ammissibile.}
{Dalla definizione}

\affermazionetrue
{I valori delle variabili di base si ricavano risolvendo il sistema di equazioni lineari determinato dai vincoli funzionali in forma aumentata.}
{Avendo il valore 0 delle variabili non in base si può risovlere il sistema di equazioni lineari per trovare il valore delle variabili in base.}

\affermazionefalse
{Una variabile nulla é certamente una variabile di base.}
{Una variabile nulla può essere sia in base, che fuori base. Una variabile fuori base è sicuramente nulla,
ma se una variabile è nulla può anche essere in base}

\affermazionetrue
{il numero delle variabili di base é sempre determinato dal numero di vincoli funzionali.}
{Proprietá numero (2) delle soluzioni di base.}

\affermazionetrue
{Se le variabili di base soddisfano i vincoli di non negativitá, la soluzione di base é una soluzione ammissibile di base.}
{Prporietá numero (5) delle soluzioni di base.}


\subsection{Dualità}
\paragraph{Si consideri un problema primale in forma di massimo. Se il duale é inammissibile, allora}:

\affermazionefalse
{Il primale é sempre illimitato come corollario del teorema della dualitá Debole}
{Il primale potrebbe anche non avere soluzioni ammissibili.}

\affermazionefalse
{Il primale ha almeno una soluzione ottima}
{Se il duale é inammissibile, allora il primale o non ha soluzioni, oppure ha funzione obiettivo illimitata, quindi il primale non ha ottimo.}

\affermazione
{Valgono le condizioni degli scarti complementari.}

\subsection{Analisi di sensitività}

\affermazionetrue
{L'analisi di sensitivitá ha l'obiettivo di identificare i Parametri Sensibili.}
{Uno degli obiettivi principali dell'analisi di sensitività è l'identificazione dei PARAMETRI SENSIBILI, vale
a dire quei parametri il cui valore non può essere modificato senza portare ad una nuova soluzione
ottimale.}

\affermazionetrue
{Un parametro é sensibile se la sua variazione porta alla variazione della soluzione ottimale.}
{I Parametri sensibili sono parametri il cui valore non può essere modificato senza portare a una nuova soluzione ottimale}

\affermazionetrue
{Dato un termine noto destro, il metodo del simplesso identifica il corrispondente prezzo ombra tramite il coefficiente
della corrispondente variabile slack nella riga zero del tableau finale.}
{}

\affermazione
{É sempre vero che un termino noto non é un parametro sensibile se il corrispondente prezzo ombra é nullo}

\affermazione
{Un termine noto é un parametro sensibile se il corrispondente prezzo ombra é positivo.}

\subsection{Metodo di Bisezione}
\affermazionetrue
{
    Si consideri il metodo di bisezione per la determinazione del punto massimo di una funzione $f(x)$: Nei punti estremi dell'intervallo
    di ricerca dell'ottimo $[l,u]$ puó succedere che i valori di $f(l)$ e $f(u)$ abbiano lo stesso segno.
}
{
    Se una funzione é pari sappiamo che $f(x)=f(-x)$, quindi possono avere lo stesso segno
}
\affermazionetrue
{Consideriamo il metodo di bisezione applicato ad una funzione convessa: se $f'(x)>0$ allora $x$ é un estremo superiore}
{Se la funzione é convessa, quando la derivata é $>0$ allora ci troviamo a destra dell'ottimo, quindi dobbiamo modificare l'estremo superiore}

\affermazione
{L'Algoritmo di Bisezione fornisce una soluzione analitica al problema di trovare un massimo (o minimo) di una funzione in una variabile}

\affermazione
{Gli algoritmi di ottimizzazione non linare permettono di individuare gli ottimi globali di una funzione continua.}

\subsection{Gradiente/Newton 2D}

\affermazionetrue
{Il metodo di Newton (se) converge, converge molto più velocemente del metodo del gradiente, ma ogni iterazione richiede uno sforzo computazionale maggiore}
{Newton potrebbe non convergere, ma se converge converge più rapidamente perchè utilizza le informazioni di Gradiente ed Hessiana invece che solo del gradiente.
Richiede uno sforzo computazionale maggiore perchè oltre che il gradiente ad ogni iterazione deve calcolare l'inversa della Hessiana}

\affermazionetrue
{Nel caso di funzioni quadratiche, il metodo di Newton converge al punto stazionario al più in una iterazione, partendo da qualsisasi punto.}

\affermazionefalse
{Il metodo di Newton converge sempre ad un punto di minimo locale.}
{Se la funzione è Concava Newton converge ad un punto di massimo.}

\affermazionefalse
{Il Metodo di Newton applicato ad una funzione continua quadratica può non convergere se il punto iniziale è lontano dal punto di ottimo}
{Il Metodo di Newton, se la funzione è quadratica, converge sempre in una iterazione.}

\subsection{KKT}
\affermazionetrue
{Le condizioni KKT rappresentano delle condizioni di ottimalitá e non un algoritmo di ottimizzazione.}

\affermazionetrue
{Le condizioni KKT non sono un algorimto di ottimizzazione.}
{Le KKT non sono un algoritmo bensí delle condizioni necessarie non sufficienti per i punti di ottimo.}

\affermazionetrue
{I punti dove il gradiente della Lagrangiana é nullo possono essere possibili candidati ad essere punti di ottimo del problema PNL corrisponendte,
ma per stabilire se sono punti di ottimo devo verificare anche altre condizioni}
{}

\affermazionetrue
{Supponendo di avere un problema di PNL vincola di massimizzazione con vincoli di $\leq$, se la funzione Lagrangiana é espressa sommando alla funzione obiettivo f la somma pesata dei vincoli, allora i pesi (moltiplicatori di lagrange) nei punti di ottimo devono essere $\geq 0$.}

\affermazionefalse
{Supponendo di avere un problema di PNL vincola di massimizzazione con vincoli di $\leq$, se la funzione Lagrangiana é espressa sommando alla funzione obiettivo f la somma pesata dei vincoli, allora i pesi (moltiplicatori di lagrange) nei punti di ottimo devono essere $\leq 0$.}

\affermazionetrue
{In un problema di $max$ con vincoli di $\geq$, la corrispondente funzione lagrangiana si ottiene sommando alla funzione oiettivo la combinazione lineare dei vincoli con pesi tutti \emph{positivi}}
{In un problema di $Max$ in cui i vincoli sono tutti di $\leq$, la lagrangiana ha i pesi $\mu$ tutti Negativi, di conseguenza, se avessimo vincoli di $\geq$ dobbiamo invertire i segni dei pesi $\mu$, rendendoli tutti positivi.}

\affermazionetrue
{In un problema di PNL Vincolata, nel punto di ottimo il gradiente della funzione $f$ puó essere riscritto come combinazione lineare dei gradienti dei vincoli.}

\affermazionefalse
{Nel punto di ottimo di un problema di PNL Vincolata il gradiente della funzione obiettivo é sempre nullo}
{In PNL Vincolata non abbiamo bisogno di sapere se il gradiente della funzione obiettivo sia nullo, perché avendo i vincoli non é detto che l'ottimo sia anche l'ottimo della f.obiettivo.}

\chapter{Domande Aperte}
\domanda[Proprietá dei Vertici Ammissibili]{3}{
    Si enuncino le Proprietà dei Vertici Ammissibili di un problema di PL. Si scelga poi una delle proprietà e si mostri un esempio grafico o numerico.
}
\rispostaaperta{
    I vertici ammissibili di un problema di PL hanno le seguenti proprietá:
    \begin{enumerate}
        \item Se esiste una sola soluzione ottima, questa sará un vertice ammissibile.
        Se esistono piú soluzioni con regione ammissibile limitata, allora almeno due di queste sono vertici ammissibili tra loro adiacenti.
        \item Il numero di vertici ammissibili é finito e dipende da n vincoli di non negativitá e m vincoli funzionali.
        il numero di combinazioni di m + n vincoli presi a gruppi di n é pari $\frac{(m+n)!}{m!n!}$. Questa quantitá (finita) rappresenta un limite superiore al numero di vertici ammissibili.
        \item Se un vertice ammissibile non ha vertici adiacenti migliori, allora non ci sono vertici migliori. 
        Quindi se il problema ha una soluzione otttima, questo vertice é la soluzione ottima.
    \end{enumerate}
}

\domanda[Proprietá di una Soluzione di Base]{4}{Si elenchino le proprietá di una Soluzione di Base}
\rispostaaperta{
    \begin{enumerate}
        \item Una variabile puó essere una variabile di base o una variabile non di base.
        \item Il numero delle variabili di base eguaglia il numero dei vincoli funzionali.
        \item La variabili non di base vengono poste a zero.
        \item I valori delle variabili di base sono ottenuti come risoluzione simultanea del sistema di equazioni lineari.
        \item Se le variabili di base soddisfano i vincoli di non negativitá, la soluzione di base é una soluzione ammissibile di base.
    \end{enumerate}
}

\domanda[Dualitá Debole e Forte]{5}{Si dia una defninizione di Dualitá Debole e Forte}
\rispostaaperta{
\begin{itemize}
    \item Dualitá Debole: Il valore della funzione obiettivo per una qualsiasi soluzione ammissibile del problema primale (max) non puó eccedere
    il valore della funzione obiettivo per una qualisasi soluzione ammissibile del problema duale.
    il valore del problema duale fornisce quindi un limite superiore del problema primale.
    Detto breve: se il primale ha soluzione illimitata allora il duale non ha soluzione.
    \item Dualitá forte: Se esiste una soluzione ottima (finita), il valore ottimo della funzione obiettivo del problema primale è uguale al valore ottimo della funzione obiettivo del problema duale.
\end{itemize}
}

\domanda[Dualitá e le proprietà]{}{Descrivere la proprietá di dualitá debole, di dualitá forte, la proprietá delle soluzioni complementari e la proprietá delle soluzioni ottimali complementare. Infine si presenti il teorema di dualitá}
\rispostaaperta{
    \subparagraph{Dualitá Debole} Dualitá Debole: Il valore della funzione obiettivo per una qualsiasi soluzione ammissibile del problema primale (max) non puó eccedere
    il valore della funzione obiettivo per una qualisasi soluzione ammissibile del problema duale.
    \subparagraph{Dualitá Forte} Se esiste una soluzione ottima (finita), il valore ottimo della funzione obiettivo del problema primale è uguale al valore ottimo della funzione obiettivo del problema duale.
    \subparagraph{Proprietá delle soluzioni Complementari} Ad ogni iterazione del metodo del simplesso, l'algoritmo calcola contemporaneamente una soluzione ammissibile per il primale e una soluzione per il duale (dato dai valori delle variabili di slack nella riga 0) i cui valori della funzione obiettivo si eguagliano. La soluzione del duale é ammissibile (e ottima) solo all'ultima iterazione del simplesso.
    \subparagraph{Proprietá delle soluzioni Ottime Complementari}  All'ultima iterazione il metodo del simplesso calcola contermporaneamente una soluzione ottima per il primale, e ottima per il duale, in cui vale la dualitá forte quindi i valori delle funizoni obiettivo si eguagliano.
    \subparagraph{Teorema della dualitá} Se il primale é ammissibile e ha funzione obiettivo limitata, quindi ha ottimo, lo stesso vale per il duale. Se il primale ha soluzioni ammissibili, ma funzione obiettivo illimitata, il duale non ha soluzioni ammissibili. Se il primale non ha soluzioni ammissibili, il duale o  non ha soluzioni ammissibili o ha funzione obiettivo illimitata. 
}

\domanda[Proprietá di Complementarietá]{9}{Si definisca la Proprietá di Complementarietá in PL. Si diano due esempi reali in cui é utilizzabile e cosa permette di concludere.}
\rispostaaperta{ %Da rivedere
    La complementarietá in un problema di Programmazione Lineare si evince dalla relazione tra problmea primale e duale.
    In particolare, la complementarietá afferma che ogni soluzione primale ha una soluzione complementare duale tale che $W=Z$
    Se un problema lineare in forma primale ha soluzione ottimale x* allora anche il problema
    }

\end{document}